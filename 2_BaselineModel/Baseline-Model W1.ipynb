{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_Brot_W1:\n",
      "0       1.0\n",
      "8       1.0\n",
      "10      1.0\n",
      "18      1.0\n",
      "20      1.0\n",
      "       ... \n",
      "9347    1.0\n",
      "9356    1.0\n",
      "9357    1.0\n",
      "9365    1.0\n",
      "9368    1.0\n",
      "Name: Warengruppe, Length: 1819, dtype: float64\n",
      "df_Broetchen_W2:\n",
      "1       2.0\n",
      "9       2.0\n",
      "11      2.0\n",
      "19      2.0\n",
      "21      2.0\n",
      "       ... \n",
      "9348    2.0\n",
      "9355    2.0\n",
      "9358    2.0\n",
      "9364    2.0\n",
      "9369    2.0\n",
      "Name: Warengruppe, Length: 1819, dtype: float64\n",
      "df_Crossaint_W3:\n",
      "2       3.0\n",
      "6       3.0\n",
      "12      3.0\n",
      "16      3.0\n",
      "22      3.0\n",
      "       ... \n",
      "9349    3.0\n",
      "9354    3.0\n",
      "9359    3.0\n",
      "9366    3.0\n",
      "9370    3.0\n",
      "Name: Warengruppe, Length: 1819, dtype: float64\n",
      "df_Konditorei_W4:\n",
      "3       4.0\n",
      "7       4.0\n",
      "13      4.0\n",
      "17      4.0\n",
      "23      4.0\n",
      "       ... \n",
      "9350    4.0\n",
      "9353    4.0\n",
      "9360    4.0\n",
      "9363    4.0\n",
      "9371    4.0\n",
      "Name: Warengruppe, Length: 1766, dtype: float64\n",
      "df_Kuchen_W5:\n",
      "4       5.0\n",
      "5       5.0\n",
      "14      5.0\n",
      "15      5.0\n",
      "24      5.0\n",
      "       ... \n",
      "9351    5.0\n",
      "9352    5.0\n",
      "9361    5.0\n",
      "9362    5.0\n",
      "9367    5.0\n",
      "Name: Warengruppe, Length: 1819, dtype: float64\n",
      "df_Saisonbrot_W6:\n",
      "567     6.0\n",
      "578     6.0\n",
      "584     6.0\n",
      "585     6.0\n",
      "596     6.0\n",
      "       ... \n",
      "8276    6.0\n",
      "8284    6.0\n",
      "8293    6.0\n",
      "8294    6.0\n",
      "8302    6.0\n",
      "Name: Warengruppe, Length: 292, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Splitting von MERGED_DATA.csv in die jeweiligen Warengruppen\n",
    "#Kann bei Bedarf in das Baseline-Modell Notebook kopiert\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Laden des merged_data.csv\n",
    "merged_data_csv = \"/workspaces/DS_ML_Gr_1.5/0_DataPreparation/merged_data_new.csv\"\n",
    "df_merged_data = pd.read_csv(merged_data_csv)\n",
    "\n",
    "df = pd.DataFrame(df_merged_data)\n",
    "\n",
    "#Bennenung der Warengruppne für dataframe Namen\n",
    "warengruppe_namen = {\n",
    "\n",
    "    1: 'Brot',\n",
    "    2: 'Broetchen',\n",
    "    3: 'Crossaint',\n",
    "    4: 'Konditorei',\n",
    "    5: 'Kuchen',\n",
    "    6: 'Saisonbrot'\n",
    "}\n",
    "\n",
    "# DataFrames dynamisch mit Namen erstellen\n",
    "for i, name in warengruppe_namen.items():\n",
    "    var_name = f\"df_{name}_W{i}\"  # Name erstellen nach: df_Brot_W1\n",
    "    globals()[var_name] = df[df['Warengruppe'] == i]\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(\"df_Brot_W1:\")\n",
    "print(df_Brot_W1[\"Warengruppe\"]) #Luisa\n",
    "\n",
    "print(\"df_Broetchen_W2:\")\n",
    "print(df_Broetchen_W2[\"Warengruppe\"]) #Luisa\n",
    "\n",
    "print(\"df_Crossaint_W3:\")\n",
    "print(df_Crossaint_W3[\"Warengruppe\"]) #Nina\n",
    "\n",
    "print(\"df_Konditorei_W4:\")\n",
    "print(df_Konditorei_W4[\"Warengruppe\"]) #Wiebke\n",
    "\n",
    "print(\"df_Kuchen_W5:\")\n",
    "print(df_Kuchen_W5[\"Warengruppe\"]) #Nina\n",
    "\n",
    "print(\"df_Saisonbrot_W6:\")\n",
    "print(df_Saisonbrot_W6[\"Warengruppe\"]) #Wiebke\n",
    "\n",
    "#Hier bekommt man nur die Warengruppenspalte und nicht den Rest, habe das in meinen Baseline Modellen so gemacht:\n",
    "# Load the dataset \n",
    "\n",
    "#data1=pd.read_csv(\"/workspaces/DS_ML_Gr_1.5/0_DataPreparation/merged_data_new.csv\")\n",
    "#Warengruppe=4\n",
    "#data = data1[data1['Warengruppe'] == Warengruppe]\n",
    "#print (data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.14.4)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.1.1)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (1.14.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.2.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Umsatz   R-squared:                       0.031\n",
      "Model:                            OLS   Adj. R-squared:                  0.030\n",
      "Method:                 Least Squares   F-statistic:                     42.71\n",
      "Date:                Sat, 07 Dec 2024   Prob (F-statistic):           9.76e-60\n",
      "Time:                        22:52:49   Log-Likelihood:                -59520.\n",
      "No. Observations:                9334   AIC:                         1.191e+05\n",
      "Df Residuals:                    9326   BIC:                         1.191e+05\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                   215.5702      4.977     43.314      0.000     205.814     225.326\n",
      "C(Wochentag)[T.Monday]       -3.0896      5.546     -0.557      0.577     -13.961       7.781\n",
      "C(Wochentag)[T.Saturday]     44.5142      5.533      8.045      0.000      33.668      55.361\n",
      "C(Wochentag)[T.Sunday]       49.7648      5.527      9.004      0.000      38.930      60.599\n",
      "C(Wochentag)[T.Thursday]     -3.4996      5.535     -0.632      0.527     -14.350       7.351\n",
      "C(Wochentag)[T.Tuesday]      -8.8103      5.524     -1.595      0.111     -19.639       2.018\n",
      "C(Wochentag)[T.Wednesday]    -9.3485      5.527     -1.691      0.091     -20.183       1.486\n",
      "Warengruppe                  -6.0863      0.989     -6.151      0.000      -8.026      -4.147\n",
      "==============================================================================\n",
      "Omnibus:                     3780.788   Durbin-Watson:                   0.273\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            31290.096\n",
      "Skew:                           1.728   Prob(JB):                         0.00\n",
      "Kurtosis:                      11.277   Cond. No.                         26.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "%pip install statsmodels\n",
    "# Import necessary libraries\n",
    "import pandas as pd  # For data manipulation and handling\n",
    "import statsmodels.formula.api as smf  # For statistical modeling\n",
    "\n",
    "# Load the dataset \n",
    "data=pd.read_csv(\"/workspaces/DS_ML_Gr_1.5/0_DataPreparation/umsatzdaten_codiert.csv\")\n",
    "\n",
    "# Fit a linear regression model\n",
    "# - 'Umsatz' is the dependent variable (target) we aim to predict.\n",
    "# - 'Warengruppe' represents the size of neighboring lots (continuous feature). (Stimmt zwar nicht, aber erstmal so als Beispiel)\n",
    "# - 'C(Wochentag)' treats the 'Wochentag' feature as a categorical variable.\n",
    "mod = smf.ols('Umsatz ~ Warengruppe+C(Wochentag)', data=data).fit()\n",
    "\n",
    "# Output the summary of the fitted model\n",
    "# The summary includes key metrics such as R-squared, coefficients, and p-values.\n",
    "print(mod.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.14.4)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.1.1)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (1.14.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.2.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "        Datum  Inflationsrate  Heimspiel  Weihnachtsmarkt  Markt  \\\n",
      "0  2013-07-01            1.53          0                0      0   \n",
      "8  2013-07-02            1.53          0                0      0   \n",
      "10 2013-07-03            1.53          0                0      0   \n",
      "18 2013-07-04            1.53          0                0      0   \n",
      "20 2013-07-05            1.53          0                0      0   \n",
      "\n",
      "   Faehrverkaehr  Kreuzfahrverkehr  Temperatur  Monat Jahreszeit  ...  Monday  \\\n",
      "0      1.576.718           419.447     17.8375    7.0     Sommer  ...     1.0   \n",
      "8      1.576.718           419.447     17.3125    7.0     Sommer  ...     0.0   \n",
      "10     1.576.718           419.447     21.0750    7.0     Sommer  ...     0.0   \n",
      "18     1.576.718           419.447     18.8500    7.0     Sommer  ...     0.0   \n",
      "20     1.576.718           419.447     19.9750    7.0     Sommer  ...     0.0   \n",
      "\n",
      "    Tuesday  Wednesday  Thursday  Friday  Saturday  Sunday  Schulferien  \\\n",
      "0       0.0        0.0       0.0     0.0       0.0     0.0          1.0   \n",
      "8       1.0        0.0       0.0     0.0       0.0     0.0          1.0   \n",
      "10      0.0        1.0       0.0     0.0       0.0     0.0          1.0   \n",
      "18      0.0        0.0       1.0     0.0       0.0     0.0          1.0   \n",
      "20      0.0        0.0       0.0     1.0       0.0     0.0          1.0   \n",
      "\n",
      "    Semesterferien Feiertage  \n",
      "0              1.0       0.0  \n",
      "8              1.0       0.0  \n",
      "10             1.0       0.0  \n",
      "18             1.0       0.0  \n",
      "20             1.0       0.0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2985/2765493519.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Datum'] = pd.to_datetime(data['Datum'])\n"
     ]
    },
    {
     "ename": "MissingDataError",
     "evalue": "exog contains inf or nans",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingDataError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m X_train \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(X_train)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Train the linear regression model using Statsmodels\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOLS\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Print the summary of the regression model\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Includes metrics like R-squared, coefficients, and p-values for each feature\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:921\u001b[0m, in \u001b[0;36mOLS.__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    918\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    919\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn exception will be raised in the next version.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    920\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, ValueWarning)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys:\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:746\u001b[0m, in \u001b[0;36mWLS.__init__\u001b[0;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    745\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m--> 746\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    748\u001b[0m nobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    749\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:200\u001b[0m, in \u001b[0;36mRegressionModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog: Float64Array \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_attr\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinv_wexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwendog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/statsmodels/base/model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/statsmodels/base/model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/statsmodels/base/model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/statsmodels/base/data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[1;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[0;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/statsmodels/base/data.py:88\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity()\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/statsmodels/base/data.py:134\u001b[0m, in \u001b[0;36mModelData._handle_constant\u001b[0;34m(self, hasconst)\u001b[0m\n\u001b[1;32m    132\u001b[0m exog_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(exog_max)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingDataError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexog contains inf or nans\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    135\u001b[0m exog_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    136\u001b[0m const_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(exog_max \u001b[38;5;241m==\u001b[39m exog_min)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[0;31mMissingDataError\u001b[0m: exog contains inf or nans"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd  # Data manipulation and handling\n",
    "import statsmodels.api as sm  # Building and summarizing regression models\n",
    "from sklearn.preprocessing import StandardScaler  # Scaling features for regression\n",
    "from sklearn.model_selection import train_test_split  # Splitting data into train and test sets\n",
    "import matplotlib.pyplot as plt  # Visualization library\n",
    "import seaborn as sns  # Advanced data visualizations\n",
    "\n",
    "# Load the dataset \n",
    "data=df_Brot_W1\n",
    "\n",
    "# Display the first few rows of the dataset for inspection\n",
    "print(data.head())\n",
    "\n",
    "# Select features and target variable\n",
    "# Features include the different Warengruppen, Monday y/n\n",
    "features = ['Sommer',\n",
    "            'Winter',\n",
    "            'Frühling',\n",
    "            'Herbst',\n",
    "            'Temp_average',\n",
    "            'Temp_warm',\n",
    "            'Temp_cold'\n",
    "            ]\n",
    "X = data[features] #target variable: Umsatz\n",
    "\n",
    "# Scale the feature data to standardize the range\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define your date thresholds\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "\n",
    "# Convert to datetime if not already\n",
    "data['Datum'] = pd.to_datetime(data['Datum'])\n",
    "# Split the data based on the date thresholds\n",
    "train_data = data[data['Datum'] <= train_end_date]\n",
    "validation_data = data[(data['Datum'] > train_end_date) & (data['Datum'] <= validation_end_date)]\n",
    "test_data = data[data['Datum'] > validation_end_date]\n",
    "\n",
    "X_train = train_data[features]\n",
    "y_train = train_data['Umsatz']\n",
    "X_test=X_validation = validation_data[features]\n",
    "y_test=y_validation = validation_data['Umsatz']\n",
    "#X_test = test_data[features] erstmal so, da die gewünschten daten, keine Daten für test Daten übrig lassen\n",
    "#y_test = test_data['Umsatz']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add a constant term to the training data for the regression intercept\n",
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "# Train the linear regression model using Statsmodels\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "# Print the summary of the regression model\n",
    "# Includes metrics like R-squared, coefficients, and p-values for each feature\n",
    "print(model.summary())\n",
    "\n",
    "# Make predictions on the test set\n",
    "X_test = sm.add_constant(X_test)  # Add constant to test set for predictions\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Predictions for test data:\", predictions)\n",
    "\n",
    "# Calculate Mean Absolute Percentage Error (MAPE) for error evaluation\n",
    "mape = (abs((y_test - predictions) / y_test).mean()) * 100\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Scatter plot: Actual vs. Predicted Umsatz\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, predictions, alpha=0.7, color=\"blue\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', color=\"red\")\n",
    "plt.xlabel(\"Actual Umsatz\")\n",
    "plt.ylabel(\"Predicted Umsatz\")\n",
    "plt.title(\"Actual vs. Predicted Umsatz\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate residuals (differences between actual and predicted Umsätze)\n",
    "residuals = y_test - predictions\n",
    "\n",
    "# Residual plot: Predicted Umsätze vs. Residuals\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(predictions, residuals, alpha=0.7, color=\"green\")\n",
    "plt.axhline(y=0, color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Umsätze\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()\n",
    "\n",
    "# Histogram of residuals to check normality\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(residuals, kde=True, color=\"purple\")\n",
    "plt.title(\"Histogram of Residuals\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame of model coefficients\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': ['Intercept'] + features,\n",
    "    'Coefficient': model.params\n",
    "})\n",
    "\n",
    "# Bar plot of feature coefficients\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Coefficient', y='Feature', data=coefficients, palette=\"Blues_r\")\n",
    "plt.title(\"Feature Coefficients\")\n",
    "plt.xlabel(\"Coefficients\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (1173358690.py, line 77)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 77\u001b[0;36m\u001b[0m\n\u001b[0;31m    sample.to_csv=('predictions.csv',index=False)\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # For data manipulation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV  # Train-test split and hyperparameter tuning\n",
    "from sklearn.linear_model import Ridge  # Ridge Regression model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error  # Evaluation metrics\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"/workspaces/DS_ML_Gr_1.5/0_DataPreparation/umsatzdaten_codiert.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset for inspection\n",
    "print(data.head())\n",
    "\n",
    "# Select features and target variable\n",
    "# Features include 'Warengruppe', 'Monday', 'Tuesday'\n",
    "features = ['Warengruppe', 'Monday', 'Tuesday']\n",
    "X = data[features]  # Independent variables\n",
    "y = data['Umsatz']  # Target variable: house price\n",
    "\n",
    "# Define your date thresholds\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "test_end_date='2019-07-03'\n",
    "\n",
    "# Convert to datetime if not already\n",
    "data['Datum'] = pd.to_datetime(data['Datum'])\n",
    "# Split the data based on the date thresholds\n",
    "train_data = data[data['Datum'] <= train_end_date]\n",
    "validation_data = data[(data['Datum'] > train_end_date) & (data['Datum'] <= validation_end_date)]\n",
    "test_data = data[(data['Datum'] > validation_end_date) & (data['Datum'] <= test_end_date)]\n",
    "\n",
    "X_train = train_data[features]\n",
    "y_train = train_data['Umsatz']\n",
    "X_validation = validation_data[features]\n",
    "y_validation = validation_data['Umsatz']\n",
    "X_test = test_data[features] \n",
    "y_test = test_data['Umsatz']\n",
    "\n",
    "# Initialize Ridge Regression model\n",
    "ridge = Ridge()\n",
    "\n",
    "# Define hyperparameter grid for alpha (regularization strength)\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1, 10, 100]  # Testing a range of regularization strengths\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object for hyperparameter tuning\n",
    "# - cv=5: 5-fold cross-validation\n",
    "# - scoring='neg_mean_absolute_error': Metric for selecting the best model (negative MAE)\n",
    "# - verbose=1: Display progress during grid search\n",
    "grid_search = GridSearchCV(estimator=ridge, param_grid=param_grid, cv=5, scoring='neg_mean_absolute_error', verbose=1)\n",
    "\n",
    "# Train Ridge Regression model using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best hyperparameters from the grid search\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Retrieve the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Calculate error metrics\n",
    "mae = mean_absolute_error(y_test, predictions)  # Mean Absolute Error\n",
    "mse = mean_squared_error(y_test, predictions)  # Mean Squared Error\n",
    "mape = (abs((y_test - predictions) / y_test).mean()) * 100  # Mean Absolute Percentage Error\n",
    "\n",
    "# Output evaluation metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "sample=pd.read_csv('sample_submission.csv')\n",
    "sample['Umsatz']=sample['Umsatz'].replace(predictions.iloc[:,0])\n",
    "\n",
    "sample.to_csv=('predictions.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
