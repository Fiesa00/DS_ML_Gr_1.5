{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Data Preparation\n",
    "\n",
    "Diese Data Preparation gilt für jede Warengruppe. Vorher immer ausführen, bevor eigens Modell durchgelaufen wird.\n",
    "\n",
    "Basiert auf eine Kopie von neural_net_data_preparation.ipynb mit unseren Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>Inflationsrate</th>\n",
       "      <th>Heimspiel</th>\n",
       "      <th>Weihnachtsmarkt</th>\n",
       "      <th>Markt</th>\n",
       "      <th>Faehrverkaehr</th>\n",
       "      <th>Kreuzfahrverkehr</th>\n",
       "      <th>Temperatur</th>\n",
       "      <th>Monat</th>\n",
       "      <th>Jahreszeit</th>\n",
       "      <th>...</th>\n",
       "      <th>Sonnenaufgang</th>\n",
       "      <th>Sonnenuntergang</th>\n",
       "      <th>Tageslaenge</th>\n",
       "      <th>Niederschlag</th>\n",
       "      <th>Sonnenschein (h)</th>\n",
       "      <th>Schneehoehe</th>\n",
       "      <th>Sonnenschein</th>\n",
       "      <th>Tageslaenge (dezimal)</th>\n",
       "      <th>KielerWoche</th>\n",
       "      <th>Werktag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.576.718</td>\n",
       "      <td>419.447</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>7</td>\n",
       "      <td>Sommer</td>\n",
       "      <td>...</td>\n",
       "      <td>4:50:12</td>\n",
       "      <td>21:56:46</td>\n",
       "      <td>17:06:34</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.576.718</td>\n",
       "      <td>419.447</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>7</td>\n",
       "      <td>Sommer</td>\n",
       "      <td>...</td>\n",
       "      <td>4:50:12</td>\n",
       "      <td>21:56:46</td>\n",
       "      <td>17:06:34</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.576.718</td>\n",
       "      <td>419.447</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>7</td>\n",
       "      <td>Sommer</td>\n",
       "      <td>...</td>\n",
       "      <td>4:50:12</td>\n",
       "      <td>21:56:46</td>\n",
       "      <td>17:06:34</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.576.718</td>\n",
       "      <td>419.447</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>7</td>\n",
       "      <td>Sommer</td>\n",
       "      <td>...</td>\n",
       "      <td>4:50:12</td>\n",
       "      <td>21:56:46</td>\n",
       "      <td>17:06:34</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.576.718</td>\n",
       "      <td>419.447</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>7</td>\n",
       "      <td>Sommer</td>\n",
       "      <td>...</td>\n",
       "      <td>4:50:12</td>\n",
       "      <td>21:56:46</td>\n",
       "      <td>17:06:34</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Datum  Inflationsrate  Heimspiel  Weihnachtsmarkt  Markt  \\\n",
       "0  2013-07-01            1.53        0.0              0.0    0.0   \n",
       "1  2013-07-01            1.53        0.0              0.0    0.0   \n",
       "2  2013-07-01            1.53        0.0              0.0    0.0   \n",
       "3  2013-07-01            1.53        0.0              0.0    0.0   \n",
       "4  2013-07-01            1.53        0.0              0.0    0.0   \n",
       "\n",
       "  Faehrverkaehr  Kreuzfahrverkehr  Temperatur  Monat Jahreszeit  ...  \\\n",
       "0     1.576.718           419.447     17.8375      7     Sommer  ...   \n",
       "1     1.576.718           419.447     17.8375      7     Sommer  ...   \n",
       "2     1.576.718           419.447     17.8375      7     Sommer  ...   \n",
       "3     1.576.718           419.447     17.8375      7     Sommer  ...   \n",
       "4     1.576.718           419.447     17.8375      7     Sommer  ...   \n",
       "\n",
       "   Sonnenaufgang  Sonnenuntergang  Tageslaenge  Niederschlag  \\\n",
       "0        4:50:12         21:56:46     17:06:34           0.3   \n",
       "1        4:50:12         21:56:46     17:06:34           0.3   \n",
       "2        4:50:12         21:56:46     17:06:34           0.3   \n",
       "3        4:50:12         21:56:46     17:06:34           0.3   \n",
       "4        4:50:12         21:56:46     17:06:34           0.3   \n",
       "\n",
       "   Sonnenschein (h)  Schneehoehe  Sonnenschein  Tageslaenge (dezimal)  \\\n",
       "0                 6            -      0.350877                   17.1   \n",
       "1                 6            -      0.350877                   17.1   \n",
       "2                 6            -      0.350877                   17.1   \n",
       "3                 6            -      0.350877                   17.1   \n",
       "4                 6            -      0.350877                   17.1   \n",
       "\n",
       "   KielerWoche Werktag  \n",
       "0          0.0       1  \n",
       "1          0.0       1  \n",
       "2          0.0       1  \n",
       "3          0.0       1  \n",
       "4          0.0       1  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Import Data\n",
    "data = pd.read_csv('/workspaces/DS_ML_Gr_1.5/2_BaselineModel/merged_data_new.csv')\n",
    "data.head()  # Print first few rows to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heimspiel          float64\n",
      "Weihnachtsmarkt    float64\n",
      "Markt              float64\n",
      "Frühling             int64\n",
      "Sommer               int64\n",
      "Herbst               int64\n",
      "Winter               int64\n",
      "Temp_warm          float64\n",
      "Temp_cold          float64\n",
      "Temp_average       float64\n",
      "Monday               int64\n",
      "Tuesday              int64\n",
      "Wednesday            int64\n",
      "Thursday             int64\n",
      "Friday               int64\n",
      "Saturday             int64\n",
      "Sunday               int64\n",
      "Schulferien        float64\n",
      "Semesterferien     float64\n",
      "Feiertage          float64\n",
      "KielerWoche        float64\n",
      "Werktag              int64\n",
      "dtype: object\n",
      "Unique Values:\n",
      " Heimspiel               [0.0, 1.0]\n",
      "Weihnachtsmarkt         [0.0, 1.0]\n",
      "Markt                   [0.0, 1.0]\n",
      "Frühling                    [0, 1]\n",
      "Sommer                      [1, 0]\n",
      "Herbst                      [0, 1]\n",
      "Winter                      [0, 1]\n",
      "Temp_warm          [0.0, 1.0, nan]\n",
      "Temp_cold          [0.0, 1.0, nan]\n",
      "Temp_average       [1.0, 0.0, nan]\n",
      "Monday                      [1, 0]\n",
      "Tuesday                     [0, 1]\n",
      "Wednesday                   [0, 1]\n",
      "Thursday                    [0, 1]\n",
      "Friday                      [0, 1]\n",
      "Saturday                    [0, 1]\n",
      "Sunday                      [0, 1]\n",
      "Schulferien             [1.0, 0.0]\n",
      "Semesterferien          [1.0, 0.0]\n",
      "Feiertage               [0.0, 1.0]\n",
      "KielerWoche             [0.0, 1.0]\n",
      "Werktag                     [1, 0]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define categorical features\n",
    "categorical_features = ['Heimspiel',\n",
    "                        'Weihnachtsmarkt',\n",
    "                        'Markt',\n",
    "                        'Frühling',\n",
    "                        'Sommer',\n",
    "                        'Herbst',\n",
    "                        'Winter',\n",
    "                        'Temp_warm',\n",
    "                        'Temp_cold',\n",
    "                        'Temp_average',\n",
    "                        'Monday',\n",
    "                        'Tuesday',\n",
    "                        'Wednesday',\n",
    "                        'Thursday',\n",
    "                        'Friday',\n",
    "                        'Saturday',\n",
    "                        'Sunday',\n",
    "                        'Schulferien',\n",
    "                        'Semesterferien',\n",
    "                        'Feiertage',\n",
    "                        'KielerWoche',\n",
    "                        'Werktag']\n",
    "\n",
    "# Inspect data types and unique values for categorical columns\n",
    "print(data[categorical_features].dtypes)\n",
    "print(\"Unique Values:\\n\",data[categorical_features].apply(lambda x: x.unique()))\n",
    "\n",
    "# Ensure categorical columns are treated as categories\n",
    "for col in categorical_features:\n",
    "    data[col] = data[col].astype('category')\n",
    "\n",
    "# Encode categorical variables using pd.get_dummies\n",
    "features = pd.get_dummies(data[categorical_features], drop_first=True, dtype=int)\n",
    "\n",
    "# Include any numeric columns that are not categorical\n",
    "features['Inflationsrate'] = data['Inflationsrate']\n",
    "features['Temperatur'] = data['Temperatur']\n",
    "features['Niederschlag'] = data['Niederschlag']\n",
    "features['Schneehoehe'] = data['Schneehoehe']\n",
    "features['Sonnenschein'] = data['Sonnenschein']\n",
    "features['Kreuzfahrverkehr'] = data['Kreuzfahrverkehr']\n",
    "features['Faehrverkaehr'] = data['Faehrverkaehr']\n",
    "features['Warengruppe'] = data['Warengruppe']\n",
    "features['Datum'] = data['Datum']\n",
    "\n",
    "\n",
    "\n",
    "# Construct the prepared data set including the dependent variable --> Umsatz\n",
    "prepared_data = pd.concat([data[['Umsatz']], features], axis=1)\n",
    "\n",
    "\n",
    "# Wenn Data imputation fertig ist, #wegnehmen\n",
    "\n",
    "# Display the shape of the prepared data set\n",
    "#print(prepared_data.shape)\n",
    "# Display the first few rows of the prepared data set\n",
    "#prepared_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9737, 32)\n",
      "       Umsatz  Heimspiel_1.0  Weihnachtsmarkt_1.0  Markt_1.0  Frühling_1  \\\n",
      "0  148.828353              0                    0          0           0   \n",
      "1  535.856285              0                    0          0           0   \n",
      "2  201.198426              0                    0          0           0   \n",
      "3   65.890169              0                    0          0           0   \n",
      "4  317.475875              0                    0          0           0   \n",
      "\n",
      "   Sommer_1  Herbst_1  Winter_1  Temp_warm_1.0  Temp_cold_1.0  ...  Werktag_1  \\\n",
      "0         1         0         0              0              0  ...          1   \n",
      "1         1         0         0              0              0  ...          1   \n",
      "2         1         0         0              0              0  ...          1   \n",
      "3         1         0         0              0              0  ...          1   \n",
      "4         1         0         0              0              0  ...          1   \n",
      "\n",
      "   Inflationsrate  Temperatur  Niederschlag  Schneehoehe  Sonnenschein  \\\n",
      "0            1.53     17.8375           0.3            0      0.350877   \n",
      "1            1.53     17.8375           0.3            0      0.350877   \n",
      "2            1.53     17.8375           0.3            0      0.350877   \n",
      "3            1.53     17.8375           0.3            0      0.350877   \n",
      "4            1.53     17.8375           0.3            0      0.350877   \n",
      "\n",
      "   Kreuzfahrverkehr  Faehrverkaehr  Warengruppe       Datum  \n",
      "0           419.447      1.576.718          1.0  2013-07-01  \n",
      "1           419.447      1.576.718          2.0  2013-07-01  \n",
      "2           419.447      1.576.718          3.0  2013-07-01  \n",
      "3           419.447      1.576.718          4.0  2013-07-01  \n",
      "4           419.447      1.576.718          5.0  2013-07-01  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "Anzahl fehlender Werte pro Spalte:\n",
      "Umsatz                 0\n",
      "Heimspiel_1.0          0\n",
      "Weihnachtsmarkt_1.0    0\n",
      "Markt_1.0              0\n",
      "Frühling_1             0\n",
      "Sommer_1               0\n",
      "Herbst_1               0\n",
      "Winter_1               0\n",
      "Temp_warm_1.0          0\n",
      "Temp_cold_1.0          0\n",
      "Temp_average_1.0       0\n",
      "Monday_1               0\n",
      "Tuesday_1              0\n",
      "Wednesday_1            0\n",
      "Thursday_1             0\n",
      "Friday_1               0\n",
      "Saturday_1             0\n",
      "Sunday_1               0\n",
      "Schulferien_1.0        0\n",
      "Semesterferien_1.0     0\n",
      "Feiertage_1.0          0\n",
      "KielerWoche_1.0        0\n",
      "Werktag_1              0\n",
      "Inflationsrate         0\n",
      "Temperatur             0\n",
      "Niederschlag           0\n",
      "Schneehoehe            0\n",
      "Sonnenschein           0\n",
      "Kreuzfahrverkehr       0\n",
      "Faehrverkaehr          0\n",
      "Warengruppe            0\n",
      "Datum                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Dieser Teil muss für die Imputationsverfahren unbedingt raus/angepasst werden!\n",
    "prepared_data = prepared_data.replace(to_replace=r'NaN', value='0', regex=True)\n",
    "prepared_data = prepared_data.replace(to_replace=r'^-$', value='0', regex=True)\n",
    "prepared_data = prepared_data.fillna(0)\n",
    "prepared_data = prepared_data.dropna()\n",
    "\n",
    "# Display the shape of the prepared data set\n",
    "print(prepared_data.shape)\n",
    "# Display the first few rows of the prepared data set\n",
    "print(prepared_data.head())\n",
    "\n",
    "# Kontrolle: Überprüfen, ob noch fehlende Werte vorhanden sind\n",
    "missing_values = prepared_data.isnull().sum()\n",
    "print(\"Anzahl fehlender Werte pro Spalte:\")\n",
    "print(missing_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Umsatz', 'Heimspiel_1.0', 'Weihnachtsmarkt_1.0', 'Markt_1.0', 'Frühling_1', 'Sommer_1', 'Herbst_1', 'Winter_1', 'Temp_warm_1.0', 'Temp_cold_1.0', 'Temp_average_1.0', 'Monday_1', 'Tuesday_1', 'Wednesday_1', 'Thursday_1', 'Friday_1', 'Saturday_1', 'Sunday_1', 'Schulferien_1.0', 'Semesterferien_1.0', 'Feiertage_1.0', 'KielerWoche_1.0', 'Werktag_1', 'Inflationsrate', 'Temperatur', 'Niederschlag', 'Schneehoehe', 'Sonnenschein', 'Kreuzfahrverkehr', 'Faehrverkaehr', 'Warengruppe', 'Datum']\n",
      "df_Brot_W1:\n",
      "      Umsatz  Heimspiel_1.0  Weihnachtsmarkt_1.0  Markt_1.0  Frühling_1  \\\n",
      "2179     0.0              1                    0          0           0   \n",
      "2180     0.0              0                    0          0           0   \n",
      "2181     0.0              0                    0          0           0   \n",
      "2182     0.0              0                    0          0           0   \n",
      "2183     0.0              0                    0          0           0   \n",
      "\n",
      "      Sommer_1  Herbst_1  Winter_1  Temp_warm_1.0  Temp_cold_1.0  ...  \\\n",
      "2179         1         0         0              1              0  ...   \n",
      "2180         1         0         0              0              0  ...   \n",
      "2181         1         0         0              1              0  ...   \n",
      "2182         1         0         0              0              0  ...   \n",
      "2183         1         0         0              0              0  ...   \n",
      "\n",
      "      Werktag_1  Inflationsrate  Temperatur  Niederschlag  Schneehoehe  \\\n",
      "2179          0            1.43     23.5375           0.0            0   \n",
      "2180          0            1.43     23.3500           0.3            0   \n",
      "2181          1            1.43     25.2500           2.1            0   \n",
      "2182          1            1.43     20.7375           4.2            0   \n",
      "2183          1            1.43     20.4500           9.9            0   \n",
      "\n",
      "      Sonnenschein  Kreuzfahrverkehr  Faehrverkaehr  Warengruppe       Datum  \n",
      "2179           0.0               0.0              0          0.0  2019-07-27  \n",
      "2180           0.0               0.0              0          0.0  2019-07-28  \n",
      "2181           0.0               0.0              0          0.0  2019-07-29  \n",
      "2182           0.0               0.0              0          0.0  2019-07-30  \n",
      "2183           0.0               0.0              0          0.0  2019-07-31  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "df_Broetchen_W2:\n",
      "      Umsatz  Heimspiel_1.0  Weihnachtsmarkt_1.0  Markt_1.0  Frühling_1  \\\n",
      "2179     0.0              1                    0          0           0   \n",
      "2180     0.0              0                    0          0           0   \n",
      "2181     0.0              0                    0          0           0   \n",
      "2182     0.0              0                    0          0           0   \n",
      "2183     0.0              0                    0          0           0   \n",
      "\n",
      "      Sommer_1  Herbst_1  Winter_1  Temp_warm_1.0  Temp_cold_1.0  ...  \\\n",
      "2179         1         0         0              1              0  ...   \n",
      "2180         1         0         0              0              0  ...   \n",
      "2181         1         0         0              1              0  ...   \n",
      "2182         1         0         0              0              0  ...   \n",
      "2183         1         0         0              0              0  ...   \n",
      "\n",
      "      Werktag_1  Inflationsrate  Temperatur  Niederschlag  Schneehoehe  \\\n",
      "2179          0            1.43     23.5375           0.0            0   \n",
      "2180          0            1.43     23.3500           0.3            0   \n",
      "2181          1            1.43     25.2500           2.1            0   \n",
      "2182          1            1.43     20.7375           4.2            0   \n",
      "2183          1            1.43     20.4500           9.9            0   \n",
      "\n",
      "      Sonnenschein  Kreuzfahrverkehr  Faehrverkaehr  Warengruppe       Datum  \n",
      "2179           0.0               0.0              0          0.0  2019-07-27  \n",
      "2180           0.0               0.0              0          0.0  2019-07-28  \n",
      "2181           0.0               0.0              0          0.0  2019-07-29  \n",
      "2182           0.0               0.0              0          0.0  2019-07-30  \n",
      "2183           0.0               0.0              0          0.0  2019-07-31  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "df_Crossaint_W3:\n",
      "      Umsatz  Heimspiel_1.0  Weihnachtsmarkt_1.0  Markt_1.0  Frühling_1  \\\n",
      "2179     0.0              1                    0          0           0   \n",
      "2180     0.0              0                    0          0           0   \n",
      "2181     0.0              0                    0          0           0   \n",
      "2182     0.0              0                    0          0           0   \n",
      "2183     0.0              0                    0          0           0   \n",
      "\n",
      "      Sommer_1  Herbst_1  Winter_1  Temp_warm_1.0  Temp_cold_1.0  ...  \\\n",
      "2179         1         0         0              1              0  ...   \n",
      "2180         1         0         0              0              0  ...   \n",
      "2181         1         0         0              1              0  ...   \n",
      "2182         1         0         0              0              0  ...   \n",
      "2183         1         0         0              0              0  ...   \n",
      "\n",
      "      Werktag_1  Inflationsrate  Temperatur  Niederschlag  Schneehoehe  \\\n",
      "2179          0            1.43     23.5375           0.0            0   \n",
      "2180          0            1.43     23.3500           0.3            0   \n",
      "2181          1            1.43     25.2500           2.1            0   \n",
      "2182          1            1.43     20.7375           4.2            0   \n",
      "2183          1            1.43     20.4500           9.9            0   \n",
      "\n",
      "      Sonnenschein  Kreuzfahrverkehr  Faehrverkaehr  Warengruppe       Datum  \n",
      "2179           0.0               0.0              0          0.0  2019-07-27  \n",
      "2180           0.0               0.0              0          0.0  2019-07-28  \n",
      "2181           0.0               0.0              0          0.0  2019-07-29  \n",
      "2182           0.0               0.0              0          0.0  2019-07-30  \n",
      "2183           0.0               0.0              0          0.0  2019-07-31  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "df_Konditorei_W4:\n",
      "      Umsatz  Heimspiel_1.0  Weihnachtsmarkt_1.0  Markt_1.0  Frühling_1  \\\n",
      "2126     0.0              1                    0          0           0   \n",
      "2127     0.0              0                    0          0           0   \n",
      "2128     0.0              0                    0          0           0   \n",
      "2129     0.0              0                    0          0           0   \n",
      "2130     0.0              0                    0          0           0   \n",
      "\n",
      "      Sommer_1  Herbst_1  Winter_1  Temp_warm_1.0  Temp_cold_1.0  ...  \\\n",
      "2126         1         0         0              1              0  ...   \n",
      "2127         1         0         0              0              0  ...   \n",
      "2128         1         0         0              1              0  ...   \n",
      "2129         1         0         0              0              0  ...   \n",
      "2130         1         0         0              0              0  ...   \n",
      "\n",
      "      Werktag_1  Inflationsrate  Temperatur  Niederschlag  Schneehoehe  \\\n",
      "2126          0            1.43     23.5375           0.0            0   \n",
      "2127          0            1.43     23.3500           0.3            0   \n",
      "2128          1            1.43     25.2500           2.1            0   \n",
      "2129          1            1.43     20.7375           4.2            0   \n",
      "2130          1            1.43     20.4500           9.9            0   \n",
      "\n",
      "      Sonnenschein  Kreuzfahrverkehr  Faehrverkaehr  Warengruppe       Datum  \n",
      "2126           0.0               0.0              0          0.0  2019-07-27  \n",
      "2127           0.0               0.0              0          0.0  2019-07-28  \n",
      "2128           0.0               0.0              0          0.0  2019-07-29  \n",
      "2129           0.0               0.0              0          0.0  2019-07-30  \n",
      "2130           0.0               0.0              0          0.0  2019-07-31  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "df_Kuchen_W5:\n",
      "      Umsatz  Heimspiel_1.0  Weihnachtsmarkt_1.0  Markt_1.0  Frühling_1  \\\n",
      "2179     0.0              1                    0          0           0   \n",
      "2180     0.0              0                    0          0           0   \n",
      "2181     0.0              0                    0          0           0   \n",
      "2182     0.0              0                    0          0           0   \n",
      "2183     0.0              0                    0          0           0   \n",
      "\n",
      "      Sommer_1  Herbst_1  Winter_1  Temp_warm_1.0  Temp_cold_1.0  ...  \\\n",
      "2179         1         0         0              1              0  ...   \n",
      "2180         1         0         0              0              0  ...   \n",
      "2181         1         0         0              1              0  ...   \n",
      "2182         1         0         0              0              0  ...   \n",
      "2183         1         0         0              0              0  ...   \n",
      "\n",
      "      Werktag_1  Inflationsrate  Temperatur  Niederschlag  Schneehoehe  \\\n",
      "2179          0            1.43     23.5375           0.0            0   \n",
      "2180          0            1.43     23.3500           0.3            0   \n",
      "2181          1            1.43     25.2500           2.1            0   \n",
      "2182          1            1.43     20.7375           4.2            0   \n",
      "2183          1            1.43     20.4500           9.9            0   \n",
      "\n",
      "      Sonnenschein  Kreuzfahrverkehr  Faehrverkaehr  Warengruppe       Datum  \n",
      "2179           0.0               0.0              0          0.0  2019-07-27  \n",
      "2180           0.0               0.0              0          0.0  2019-07-28  \n",
      "2181           0.0               0.0              0          0.0  2019-07-29  \n",
      "2182           0.0               0.0              0          0.0  2019-07-30  \n",
      "2183           0.0               0.0              0          0.0  2019-07-31  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "df_Saisonbrot_W6:\n",
      "     Umsatz  Heimspiel_1.0  Weihnachtsmarkt_1.0  Markt_1.0  Frühling_1  \\\n",
      "652     0.0              1                    0          0           0   \n",
      "653     0.0              0                    0          0           0   \n",
      "654     0.0              0                    0          0           0   \n",
      "655     0.0              0                    0          0           0   \n",
      "656     0.0              0                    0          0           0   \n",
      "\n",
      "     Sommer_1  Herbst_1  Winter_1  Temp_warm_1.0  Temp_cold_1.0  ...  \\\n",
      "652         1         0         0              1              0  ...   \n",
      "653         1         0         0              0              0  ...   \n",
      "654         1         0         0              1              0  ...   \n",
      "655         1         0         0              0              0  ...   \n",
      "656         1         0         0              0              0  ...   \n",
      "\n",
      "     Werktag_1  Inflationsrate  Temperatur  Niederschlag  Schneehoehe  \\\n",
      "652          0            1.43     23.5375           0.0            0   \n",
      "653          0            1.43     23.3500           0.3            0   \n",
      "654          1            1.43     25.2500           2.1            0   \n",
      "655          1            1.43     20.7375           4.2            0   \n",
      "656          1            1.43     20.4500           9.9            0   \n",
      "\n",
      "     Sonnenschein  Kreuzfahrverkehr  Faehrverkaehr  Warengruppe       Datum  \n",
      "652           0.0               0.0              0          0.0  2019-07-27  \n",
      "653           0.0               0.0              0          0.0  2019-07-28  \n",
      "654           0.0               0.0              0          0.0  2019-07-29  \n",
      "655           0.0               0.0              0          0.0  2019-07-30  \n",
      "656           0.0               0.0              0          0.0  2019-07-31  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "#Splitting des Datensets in die jeweiligen Warengruppen\n",
    "\n",
    "#Bennenung der Warengruppne für dataframe Namen\n",
    "warengruppe_namen = {\n",
    "    1: 'Brot',\n",
    "    2: 'Broetchen',\n",
    "    3: 'Crossaint',\n",
    "    4: 'Konditorei',\n",
    "    5: 'Kuchen',\n",
    "    6: 'Saisonbrot'\n",
    "}\n",
    "\n",
    "# Ursprüngliche DataFrames filtern nach Warengruppe\n",
    "warengruppe_dataframes = {}\n",
    "for i, name in warengruppe_namen.items():\n",
    "    var_name = f\"df_{name}_W{i}\"  # Name erstellen nach: df_Brot_W1\n",
    "    warengruppe_dataframes[var_name] = prepared_data[\n",
    "        (prepared_data['Warengruppe'] == i) &\n",
    "        (prepared_data['Datum'] <= '2018-07-31')\n",
    "    ]\n",
    "\n",
    "# Daten bis 2019-07-31 unabhängig der Warengruppe hinzufügen\n",
    "new_data = prepared_data[\n",
    "    (prepared_data['Datum'] > '2018-07-31') &\n",
    "    (prepared_data['Datum'] <= '2019-08-31')\n",
    "]\n",
    "\n",
    "for var_name, df in warengruppe_dataframes.items():\n",
    "    updated_df = pd.concat([df, new_data], ignore_index=True)\n",
    "    globals()[var_name] = updated_df\n",
    "\n",
    "column_names = df_Brot_W1.columns.tolist()\n",
    "print(column_names)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(\"df_Brot_W1:\")\n",
    "print(df_Brot_W1.tail()) #Luisa\n",
    "\n",
    "print(\"df_Broetchen_W2:\")\n",
    "print(df_Broetchen_W2.tail()) #Luisa\n",
    "\n",
    "print(\"df_Crossaint_W3:\")\n",
    "print(df_Crossaint_W3.tail()) #Nina\n",
    "\n",
    "print(\"df_Konditorei_W4:\")\n",
    "print(df_Konditorei_W4.tail()) #Wiebke\n",
    "\n",
    "print(\"df_Kuchen_W5:\")\n",
    "print(df_Kuchen_W5.tail()) #Nina\n",
    "\n",
    "print(\"df_Saisonbrot_W6:\")\n",
    "print(df_Saisonbrot_W6.tail()) #Wiebke\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W1_Brot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features dimensions: (1462, 19)\n",
      "Validation features dimensions: (357, 19)\n",
      "Test features dimensions: (364, 19)\n",
      "\n",
      "Training labels dimensions: (1462, 1)\n",
      "Validation labels dimensions: (357, 1)\n",
      "Test labels dimensions: (364, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4557/33898857.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Datum'] = pd.to_datetime(data['Datum'])\n"
     ]
    }
   ],
   "source": [
    "data = df_Brot_W1\n",
    "\n",
    "\n",
    "# Define your date thresholds\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "test_end_date='2019-07-30'\n",
    "\n",
    "#Keep only wanted features\n",
    "data=data[['Datum',\n",
    "           'Umsatz',\n",
    "           'Warengruppe',\n",
    "            #Hier Features hinzufügen und Namen anpassen:\n",
    "           'Sommer_1',\n",
    "            'Winter_1',\n",
    "            'Temp_average_1.0',\n",
    "            'Temp_warm_1.0',\n",
    "            'Temp_cold_1.0',\n",
    "            'Feiertage_1.0',\n",
    "            'Schulferien_1.0',\n",
    "            'Semesterferien_1.0',\n",
    "            'Monday_1',\n",
    "            'Tuesday_1',\n",
    "            'Wednesday_1',\n",
    "            'Thursday_1',\n",
    "            'Friday_1',\n",
    "            'Saturday_1',\n",
    "            'Sunday_1',\n",
    "            'Weihnachtsmarkt_1.0',\n",
    "            'Markt_1.0',\n",
    "            'Heimspiel_1.0',\n",
    "            'KielerWoche_1.0']]\n",
    "\n",
    "# Convert to datetime if not already\n",
    "data['Datum'] = pd.to_datetime(data['Datum'])\n",
    "\n",
    "# Split the data based on the date thresholds\n",
    "training_data = data[data['Datum'] <= train_end_date]\n",
    "validation_data = data[(data['Datum'] > train_end_date) & (data['Datum'] <= validation_end_date)]\n",
    "test_data = data[(data['Datum'] > validation_end_date) & (data['Datum'] <= test_end_date)]\n",
    "\n",
    "# Separating features and labels\n",
    "training_features = training_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "validation_features = validation_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "test_features = test_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "\n",
    "training_labels = training_data[['Umsatz']]\n",
    "validation_labels = validation_data[['Umsatz']]\n",
    "test_labels = test_data[['Umsatz']]\n",
    "\n",
    "# Print dimensions of the dataframes\n",
    "print(\"Training features dimensions:\", training_features.shape)\n",
    "print(\"Validation features dimensions:\", validation_features.shape)\n",
    "print(\"Test features dimensions:\", test_features.shape)\n",
    "print()\n",
    "print(\"Training labels dimensions:\", training_labels.shape)\n",
    "print(\"Validation labels dimensions:\", validation_labels.shape)\n",
    "print(\"Test labels dimensions:\", test_labels.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectory for the pickle files\n",
    "subdirectory = \"pickle_data//W1_Brot\"\n",
    "os.makedirs(subdirectory, exist_ok=True)\n",
    "\n",
    "# Export of the prepared data to subdirectory as pickle files\n",
    "training_features.to_pickle(f\"{subdirectory}/training_features.pkl\")\n",
    "validation_features.to_pickle(f\"{subdirectory}/validation_features.pkl\")\n",
    "test_features.to_pickle(f\"{subdirectory}/test_features.pkl\")\n",
    "training_labels.to_pickle(f\"{subdirectory}/training_labels.pkl\")\n",
    "validation_labels.to_pickle(f\"{subdirectory}/validation_labels.pkl\")\n",
    "test_labels.to_pickle(f\"{subdirectory}/test_labels.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W2_Broetchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features dimensions: (1462, 15)\n",
      "Validation features dimensions: (357, 15)\n",
      "Test features dimensions: (364, 15)\n",
      "\n",
      "Training labels dimensions: (1462, 1)\n",
      "Validation labels dimensions: (357, 1)\n",
      "Test labels dimensions: (364, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4557/138920424.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Datum'] = pd.to_datetime(data['Datum'])\n"
     ]
    }
   ],
   "source": [
    "data = df_Broetchen_W2\n",
    "\n",
    "# Define your date thresholds\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "test_end_date='2019-07-30'\n",
    "\n",
    "#Keep only wanted features\n",
    "data=data[['Umsatz',\n",
    "           'Datum',\n",
    "           'Warengruppe',\n",
    "            #Hier Features hinzufügen und Namen anpassen:\n",
    "            'Werktag_1',\n",
    "            'Weihnachtsmarkt_1.0',\n",
    "            'Markt_1.0',\n",
    "            'Herbst_1',\n",
    "            'Frühling_1',\n",
    "            'Sommer_1',\n",
    "            'Winter_1',\n",
    "            'Temp_average_1.0',\n",
    "            'Temp_warm_1.0',\n",
    "            'Temp_cold_1.0',\n",
    "            'Feiertage_1.0',\n",
    "            'Schulferien_1.0',\n",
    "            'Semesterferien_1.0',\n",
    "            'Heimspiel_1.0',\n",
    "            'KielerWoche_1.0']]\n",
    "\n",
    "# Convert to datetime if not already\n",
    "data['Datum'] = pd.to_datetime(data['Datum'])\n",
    "\n",
    "# Split the data based on the date thresholds\n",
    "training_data = data[data['Datum'] <= train_end_date]\n",
    "validation_data = data[(data['Datum'] > train_end_date) & (data['Datum'] <= validation_end_date)]\n",
    "test_data = data[(data['Datum'] > validation_end_date) & (data['Datum'] <= test_end_date)]\n",
    "\n",
    "# Separating features and labels\n",
    "training_features = training_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "validation_features = validation_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "test_features = test_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "\n",
    "training_labels = training_data[['Umsatz']]\n",
    "validation_labels = validation_data[['Umsatz']]\n",
    "test_labels = test_data[['Umsatz']]\n",
    "\n",
    "# Print dimensions of the dataframes\n",
    "print(\"Training features dimensions:\", training_features.shape)\n",
    "print(\"Validation features dimensions:\", validation_features.shape)\n",
    "print(\"Test features dimensions:\", test_features.shape)\n",
    "print()\n",
    "print(\"Training labels dimensions:\", training_labels.shape)\n",
    "print(\"Validation labels dimensions:\", validation_labels.shape)\n",
    "print(\"Test labels dimensions:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectory for the pickle files\n",
    "subdirectory = \"pickle_data//W2_Broetchen\"\n",
    "os.makedirs(subdirectory, exist_ok=True)\n",
    "\n",
    "# Export of the prepared data to subdirectory as pickle files\n",
    "training_features.to_pickle(f\"{subdirectory}/training_features.pkl\")\n",
    "validation_features.to_pickle(f\"{subdirectory}/validation_features.pkl\")\n",
    "test_features.to_pickle(f\"{subdirectory}/test_features.pkl\")\n",
    "training_labels.to_pickle(f\"{subdirectory}/training_labels.pkl\")\n",
    "validation_labels.to_pickle(f\"{subdirectory}/validation_labels.pkl\")\n",
    "test_labels.to_pickle(f\"{subdirectory}/test_labels.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W3_Croissants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Umsatz', 'Heimspiel_1.0', 'Weihnachtsmarkt_1.0', 'Markt_1.0', 'Frühling_1', 'Sommer_1', 'Herbst_1', 'Winter_1', 'Temp_warm_1.0', 'Temp_cold_1.0', 'Temp_average_1.0', 'Monday_1', 'Tuesday_1', 'Wednesday_1', 'Thursday_1', 'Friday_1', 'Saturday_1', 'Sunday_1', 'Schulferien_1.0', 'Semesterferien_1.0', 'Feiertage_1.0', 'KielerWoche_1.0', 'Werktag_1', 'Inflationsrate', 'Temperatur', 'Niederschlag', 'Schneehoehe', 'Sonnenschein', 'Kreuzfahrverkehr', 'Faehrverkaehr', 'Warengruppe', 'Datum']\n"
     ]
    }
   ],
   "source": [
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features dimensions: (1462, 17)\n",
      "Validation features dimensions: (357, 17)\n",
      "Test features dimensions: (364, 17)\n",
      "\n",
      "Training labels dimensions: (1462, 1)\n",
      "Validation labels dimensions: (357, 1)\n",
      "Test labels dimensions: (364, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4557/1123981483.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Datum'] = pd.to_datetime(data['Datum'])\n"
     ]
    }
   ],
   "source": [
    "data = df_Crossaint_W3\n",
    "\n",
    "# Define your date thresholds\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "test_end_date='2019-07-30'\n",
    "\n",
    "#Keep only wanted features\n",
    "data=data[['Umsatz',\n",
    "           'Datum',\n",
    "           'Warengruppe',\n",
    "            #Hier Features hinzufügen und Namen anpassen:\n",
    "           'Sommer_1',\n",
    "           'Winter_1',\n",
    "           'Temp_cold_1.0',\n",
    "           'Temp_warm_1.0',\n",
    "           'Temp_average_1.0',\n",
    "           'Monday_1',\n",
    "           'Wednesday_1',\n",
    "           'Thursday_1',\n",
    "           'Saturday_1',\n",
    "           'Sunday_1',\n",
    "           'Schulferien_1.0',\n",
    "           'Semesterferien_1.0',\n",
    "           'Feiertage_1.0',\n",
    "           'Markt_1.0',   \n",
    "           'Sonnenschein',\n",
    "           'Niederschlag',\n",
    "           'Tageslaenge',\n",
    "           'Weihnachtsmarkt_1.0']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert to datetime if not already\n",
    "data['Datum'] = pd.to_datetime(data['Datum'])\n",
    "\n",
    "# Split the data based on the date thresholds\n",
    "training_data = data[data['Datum'] <= train_end_date]\n",
    "validation_data = data[(data['Datum'] > train_end_date) & (data['Datum'] <= validation_end_date)]\n",
    "test_data = data[(data['Datum'] > validation_end_date) & (data['Datum'] <= test_end_date)]\n",
    "\n",
    "# Separating features and labels\n",
    "training_features = training_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "validation_features = validation_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "test_features = test_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "\n",
    "training_labels = training_data[['Umsatz']]\n",
    "validation_labels = validation_data[['Umsatz']]\n",
    "test_labels = test_data[['Umsatz']]\n",
    "\n",
    "# Print dimensions of the dataframes\n",
    "print(\"Training features dimensions:\", training_features.shape)\n",
    "print(\"Validation features dimensions:\", validation_features.shape)\n",
    "print(\"Test features dimensions:\", test_features.shape)\n",
    "print()\n",
    "print(\"Training labels dimensions:\", training_labels.shape)\n",
    "print(\"Validation labels dimensions:\", validation_labels.shape)\n",
    "print(\"Test labels dimensions:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectory for the pickle files\n",
    "subdirectory = \"pickle_data//W3_Croissants\"\n",
    "os.makedirs(subdirectory, exist_ok=True)\n",
    "\n",
    "# Export of the prepared data to subdirectory as pickle files\n",
    "training_features.to_pickle(f\"{subdirectory}/training_features.pkl\")\n",
    "validation_features.to_pickle(f\"{subdirectory}/validation_features.pkl\")\n",
    "test_features.to_pickle(f\"{subdirectory}/test_features.pkl\")\n",
    "training_labels.to_pickle(f\"{subdirectory}/training_labels.pkl\")\n",
    "validation_labels.to_pickle(f\"{subdirectory}/validation_labels.pkl\")\n",
    "test_labels.to_pickle(f\"{subdirectory}/test_labels.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W4_Konditorei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Sommer_1.0', 'Herbst_1.0', 'Saturday_1.0', 'Werktag_1.0'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m test_end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2019-07-30\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#Keep only wanted features\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m data\u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUmsatz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDatum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWarengruppe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInflationsrate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHeimspiel_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMarkt_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTemperatur\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSchulferien_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSommer_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHerbst_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSaturday_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mKielerWoche_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFeiertage_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNiederschlag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSchneehoehe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSonnenschein\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWeihnachtsmarkt_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSemesterferien_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWerktag_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Convert to datetime if not already\u001b[39;00m\n\u001b[1;32m     12\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatum\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatum\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Sommer_1.0', 'Herbst_1.0', 'Saturday_1.0', 'Werktag_1.0'] not in index\""
     ]
    }
   ],
   "source": [
    "data = df_Konditorei_W4\n",
    "\n",
    "# Define your date thresholds\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "test_end_date='2019-07-30'\n",
    "\n",
    "#Keep only wanted features\n",
    "data=data[['Umsatz','Datum','Warengruppe','Inflationsrate','Heimspiel_1.0','Markt_1.0', 'Temperatur', 'Schulferien_1.0','Sommer_1.0','Herbst_1.0','Saturday_1.0','KielerWoche_1.0','Feiertage_1.0', 'Niederschlag','Schneehoehe','Sonnenschein','Weihnachtsmarkt_1.0','Semesterferien_1.0','Werktag_1.0']]\n",
    "\n",
    "# Convert to datetime if not already\n",
    "data['Datum'] = pd.to_datetime(data['Datum'])\n",
    "\n",
    "# Split the data based on the date thresholds\n",
    "training_data = data[data['Datum'] <= train_end_date]\n",
    "validation_data = data[(data['Datum'] > train_end_date) & (data['Datum'] <= validation_end_date)]\n",
    "test_data = data[(data['Datum'] > validation_end_date) & (data['Datum'] <= test_end_date)]\n",
    "\n",
    "# Separating features and labels\n",
    "training_features = training_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "validation_features = validation_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "test_features = test_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "\n",
    "training_labels = training_data[['Umsatz']]\n",
    "validation_labels = validation_data[['Umsatz']]\n",
    "test_labels = test_data[['Umsatz']]\n",
    "\n",
    "# Print dimensions of the dataframes\n",
    "print(\"Training features dimensions:\", training_features.shape)\n",
    "print(\"Validation features dimensions:\", validation_features.shape)\n",
    "print(\"Test features dimensions:\", test_features.shape)\n",
    "print()\n",
    "print(\"Training labels dimensions:\", training_labels.shape)\n",
    "print(\"Validation labels dimensions:\", validation_labels.shape)\n",
    "print(\"Test labels dimensions:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectory for the pickle files\n",
    "subdirectory = \"pickle_data//W4_Konditorei\"\n",
    "os.makedirs(subdirectory, exist_ok=True)\n",
    "\n",
    "# Export of the prepared data to subdirectory as pickle files\n",
    "training_features.to_pickle(f\"{subdirectory}/training_features.pkl\")\n",
    "validation_features.to_pickle(f\"{subdirectory}/validation_features.pkl\")\n",
    "test_features.to_pickle(f\"{subdirectory}/test_features.pkl\")\n",
    "training_labels.to_pickle(f\"{subdirectory}/training_labels.pkl\")\n",
    "validation_labels.to_pickle(f\"{subdirectory}/validation_labels.pkl\")\n",
    "test_labels.to_pickle(f\"{subdirectory}/test_labels.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W5_Kuchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features dimensions: (1462, 14)\n",
      "Validation features dimensions: (357, 14)\n",
      "Test features dimensions: (364, 14)\n",
      "\n",
      "Training labels dimensions: (1462, 1)\n",
      "Validation labels dimensions: (357, 1)\n",
      "Test labels dimensions: (364, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4557/4277134336.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Datum'] = pd.to_datetime(data['Datum'])\n"
     ]
    }
   ],
   "source": [
    "data = df_Kuchen_W5\n",
    "\n",
    "# Define your date thresholds\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "test_end_date='2019-07-30'\n",
    "\n",
    "#Keep only wanted features\n",
    "data=data[['Umsatz',\n",
    "           'Datum',\n",
    "           'Warengruppe',\n",
    "            #Hier Features hinzufügen und Namen anpassen:\n",
    "           'Markt_1.0',\n",
    "           'Sonnenschein',\n",
    "           'Niederschlag',\n",
    "           'Tageslaenge',\n",
    "           'Sommer_1',\n",
    "           'Herbst_1',\n",
    "           'Winter_1',\n",
    "           'Wednesday_1',\n",
    "           'Friday_1',\n",
    "           'Saturday_1',\n",
    "           'Sunday_1',\n",
    "           'Semesterferien_1.0',\n",
    "           'Temp_average_1.0',\n",
    "           'KielerWoche_1.0',\n",
    "           'Werktag_1']]\n",
    "\n",
    "# Convert to datetime if not already\n",
    "data['Datum'] = pd.to_datetime(data['Datum'])\n",
    "\n",
    "# Split the data based on the date thresholds\n",
    "training_data = data[data['Datum'] <= train_end_date]\n",
    "validation_data = data[(data['Datum'] > train_end_date) & (data['Datum'] <= validation_end_date)]\n",
    "test_data = data[(data['Datum'] > validation_end_date) & (data['Datum'] <= test_end_date)]\n",
    "\n",
    "# Separating features and labels\n",
    "training_features = training_data.drop(['Umsatz','Datum','Warengruppe'], axis=1)\n",
    "validation_features = validation_data.drop(['Umsatz','Datum','Warengruppe'], axis=1)\n",
    "test_features = test_data.drop(['Umsatz','Datum','Warengruppe'], axis=1)\n",
    "\n",
    "training_labels = training_data[['Umsatz']]\n",
    "validation_labels = validation_data[['Umsatz']]\n",
    "test_labels = test_data[['Umsatz']]\n",
    "\n",
    "# Print dimensions of the dataframes\n",
    "print(\"Training features dimensions:\", training_features.shape)\n",
    "print(\"Validation features dimensions:\", validation_features.shape)\n",
    "print(\"Test features dimensions:\", test_features.shape)\n",
    "print()\n",
    "print(\"Training labels dimensions:\", training_labels.shape)\n",
    "print(\"Validation labels dimensions:\", validation_labels.shape)\n",
    "print(\"Test labels dimensions:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectory for the pickle files\n",
    "subdirectory = \"pickle_data//W5_Kuchen\"\n",
    "os.makedirs(subdirectory, exist_ok=True)\n",
    "\n",
    "# Export of the prepared data to subdirectory as pickle files\n",
    "training_features.to_pickle(f\"{subdirectory}/training_features.pkl\")\n",
    "validation_features.to_pickle(f\"{subdirectory}/validation_features.pkl\")\n",
    "test_features.to_pickle(f\"{subdirectory}/test_features.pkl\")\n",
    "training_labels.to_pickle(f\"{subdirectory}/training_labels.pkl\")\n",
    "validation_labels.to_pickle(f\"{subdirectory}/validation_labels.pkl\")\n",
    "test_labels.to_pickle(f\"{subdirectory}/test_labels.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W6_Saisonbrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Umsatz', 'Heimspiel_1.0', 'Weihnachtsmarkt_1.0', 'Markt_1.0',\n",
      "       'Frühling_1', 'Sommer_1', 'Herbst_1', 'Winter_1', 'Temp_warm_1.0',\n",
      "       'Temp_cold_1.0', 'Temp_average_1.0', 'Monday_1', 'Tuesday_1',\n",
      "       'Wednesday_1', 'Thursday_1', 'Friday_1', 'Saturday_1', 'Sunday_1',\n",
      "       'Schulferien_1.0', 'Semesterferien_1.0', 'Feiertage_1.0',\n",
      "       'KielerWoche_1.0', 'Werktag_1', 'Inflationsrate', 'Temperatur',\n",
      "       'Niederschlag', 'Schneehoehe', 'Sonnenschein', 'Kreuzfahrverkehr',\n",
      "       'Faehrverkaehr', 'Warengruppe', 'Datum'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Friday_1.0', 'Werktag_1.0'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m test_end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2019-07-30\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#Keep only wanted features\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m data\u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUmsatz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDatum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWarengruppe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWeihnachtsmarkt_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTemperatur\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFriday_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSonnenschein\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWerktag_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Convert to datetime if not already\u001b[39;00m\n\u001b[1;32m     12\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatum\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatum\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Friday_1.0', 'Werktag_1.0'] not in index\""
     ]
    }
   ],
   "source": [
    "data = df_Saisonbrot_W6\n",
    "print (data.columns)\n",
    "# Define your date thresholds\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "test_end_date='2019-07-30'\n",
    "\n",
    "#Keep only wanted features\n",
    "data=data[['Umsatz','Datum','Warengruppe','Weihnachtsmarkt_1.0','Temperatur' ,'Friday_1.0','Sonnenschein','Werktag_1.0']]\n",
    "\n",
    "# Convert to datetime if not already\n",
    "data['Datum'] = pd.to_datetime(data['Datum'])\n",
    "\n",
    "# Split the data based on the date thresholds\n",
    "training_data = data[data['Datum'] <= train_end_date]\n",
    "validation_data = data[(data['Datum'] > train_end_date) & (data['Datum'] <= validation_end_date)]\n",
    "test_data = data[(data['Datum'] > validation_end_date) & (data['Datum'] <= test_end_date)]\n",
    "\n",
    "# Separating features and labels\n",
    "training_features = training_data.drop(['Umsatz','Datum','Warengruppe'], axis=1)\n",
    "validation_features = validation_data.drop(['Umsatz','Datum','Warengruppe'], axis=1)\n",
    "test_features = test_data.drop(['Umsatz','Datum','Warengruppe'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "training_labels = training_data[['Umsatz']]\n",
    "validation_labels = validation_data[['Umsatz']]\n",
    "test_labels = test_data[['Umsatz']]\n",
    "\n",
    "# Print dimensions of the dataframes\n",
    "print(\"Training features dimensions:\", training_features.shape)\n",
    "print(\"Validation features dimensions:\", validation_features.shape)\n",
    "print(\"Test features dimensions:\", test_features.shape)\n",
    "print()\n",
    "print(\"Training labels dimensions:\", training_labels.shape)\n",
    "print(\"Validation labels dimensions:\", validation_labels.shape)\n",
    "print(\"Test labels dimensions:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectory for the pickle files\n",
    "subdirectory = \"pickle_data//W6_Saisonbrot\"\n",
    "os.makedirs(subdirectory, exist_ok=True)\n",
    "\n",
    "# Export of the prepared data to subdirectory as pickle files\n",
    "training_features.to_pickle(f\"{subdirectory}/training_features.pkl\")\n",
    "validation_features.to_pickle(f\"{subdirectory}/validation_features.pkl\")\n",
    "test_features.to_pickle(f\"{subdirectory}/test_features.pkl\")\n",
    "training_labels.to_pickle(f\"{subdirectory}/training_labels.pkl\")\n",
    "validation_labels.to_pickle(f\"{subdirectory}/validation_labels.pkl\")\n",
    "test_labels.to_pickle(f\"{subdirectory}/test_labels.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
