{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Data Preparation\n",
    "\n",
    "Diese Data Preparation gilt für jede Warengruppe. Vorher immer ausführen, bevor eigens Modell durchgelaufen wird.\n",
    "\n",
    "Basiert auf eine Kopie von neural_net_data_preparation.ipynb mit unseren Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inflationsrate</th>\n",
       "      <th>Heimspiel</th>\n",
       "      <th>Weihnachtsmarkt</th>\n",
       "      <th>Markt</th>\n",
       "      <th>Faehrverkaehr</th>\n",
       "      <th>Kreuzfahrverkehr</th>\n",
       "      <th>Temperatur</th>\n",
       "      <th>Monat</th>\n",
       "      <th>Frühling</th>\n",
       "      <th>Sommer</th>\n",
       "      <th>...</th>\n",
       "      <th>Sonnenschein</th>\n",
       "      <th>Tageslaenge (dezimal)</th>\n",
       "      <th>KielerWoche</th>\n",
       "      <th>Werktag</th>\n",
       "      <th>Datum</th>\n",
       "      <th>Umsatz</th>\n",
       "      <th>Warengruppe</th>\n",
       "      <th>Temp_average</th>\n",
       "      <th>Temp_cold</th>\n",
       "      <th>Temp_warm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1576718.0</td>\n",
       "      <td>419447.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>148.828353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1576718.0</td>\n",
       "      <td>419447.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>535.856285</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1576718.0</td>\n",
       "      <td>419447.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>201.198426</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1576718.0</td>\n",
       "      <td>419447.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>65.890169</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1576718.0</td>\n",
       "      <td>419447.0</td>\n",
       "      <td>17.8375</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>317.475875</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Inflationsrate  Heimspiel  Weihnachtsmarkt  Markt  Faehrverkaehr  \\\n",
       "0            1.53        0.0              0.0    0.0      1576718.0   \n",
       "1            1.53        0.0              0.0    0.0      1576718.0   \n",
       "2            1.53        0.0              0.0    0.0      1576718.0   \n",
       "3            1.53        0.0              0.0    0.0      1576718.0   \n",
       "4            1.53        0.0              0.0    0.0      1576718.0   \n",
       "\n",
       "   Kreuzfahrverkehr  Temperatur  Monat  Frühling  Sommer  ...  Sonnenschein  \\\n",
       "0          419447.0     17.8375    7.0       0.0     1.0  ...      0.350877   \n",
       "1          419447.0     17.8375    7.0       0.0     1.0  ...      0.350877   \n",
       "2          419447.0     17.8375    7.0       0.0     1.0  ...      0.350877   \n",
       "3          419447.0     17.8375    7.0       0.0     1.0  ...      0.350877   \n",
       "4          419447.0     17.8375    7.0       0.0     1.0  ...      0.350877   \n",
       "\n",
       "   Tageslaenge (dezimal)  KielerWoche  Werktag       Datum      Umsatz  \\\n",
       "0                   17.1          0.0      1.0  2013-07-01  148.828353   \n",
       "1                   17.1          0.0      1.0  2013-07-01  535.856285   \n",
       "2                   17.1          0.0      1.0  2013-07-01  201.198426   \n",
       "3                   17.1          0.0      1.0  2013-07-01   65.890169   \n",
       "4                   17.1          0.0      1.0  2013-07-01  317.475875   \n",
       "\n",
       "   Warengruppe  Temp_average  Temp_cold  Temp_warm  \n",
       "0          1.0           1.0        0.0        0.0  \n",
       "1          2.0           1.0        0.0        0.0  \n",
       "2          3.0           1.0        0.0        0.0  \n",
       "3          4.0           1.0        0.0        0.0  \n",
       "4          5.0           1.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Import Data\n",
    "data = pd.read_csv('/workspaces/DS_ML_Gr_1.5/3_Neuronal_Model/Imputed_Data_KNN.csv')\n",
    "data.head()  # Print first few rows to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heimspiel          float64\n",
      "Weihnachtsmarkt    float64\n",
      "Markt              float64\n",
      "Frühling           float64\n",
      "Sommer             float64\n",
      "Herbst             float64\n",
      "Winter             float64\n",
      "Temp_warm          float64\n",
      "Temp_cold          float64\n",
      "Temp_average       float64\n",
      "Monday             float64\n",
      "Tuesday            float64\n",
      "Wednesday          float64\n",
      "Thursday           float64\n",
      "Friday             float64\n",
      "Saturday           float64\n",
      "Sunday             float64\n",
      "Schulferien        float64\n",
      "Semesterferien     float64\n",
      "Feiertage          float64\n",
      "KielerWoche        float64\n",
      "Werktag            float64\n",
      "dtype: object\n",
      "Unique Values:\n",
      "    Heimspiel  Weihnachtsmarkt  Markt  Frühling  Sommer  Herbst  Winter  \\\n",
      "0        0.0              0.0    0.0       0.0     1.0     0.0     0.0   \n",
      "1        1.0              1.0    1.0       1.0     0.0     1.0     1.0   \n",
      "\n",
      "   Temp_warm  Temp_cold  Temp_average  ...  Wednesday  Thursday  Friday  \\\n",
      "0        0.0        0.0           1.0  ...        0.0       0.0     0.0   \n",
      "1        1.0        1.0           0.0  ...        1.0       1.0     1.0   \n",
      "\n",
      "   Saturday  Sunday  Schulferien  Semesterferien  Feiertage  KielerWoche  \\\n",
      "0       0.0     0.0          1.0             1.0        0.0          0.0   \n",
      "1       1.0     1.0          0.0             0.0        1.0          1.0   \n",
      "\n",
      "   Werktag  \n",
      "0      1.0  \n",
      "1      0.0  \n",
      "\n",
      "[2 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define categorical features\n",
    "categorical_features = ['Heimspiel',\n",
    "                        'Weihnachtsmarkt',\n",
    "                        'Markt',\n",
    "                        'Frühling',\n",
    "                        'Sommer',\n",
    "                        'Herbst',\n",
    "                        'Winter',\n",
    "                        'Temp_warm',\n",
    "                        'Temp_cold',\n",
    "                        'Temp_average',\n",
    "                        'Monday',\n",
    "                        'Tuesday',\n",
    "                        'Wednesday',\n",
    "                        'Thursday',\n",
    "                        'Friday',\n",
    "                        'Saturday',\n",
    "                        'Sunday',\n",
    "                        'Schulferien',\n",
    "                        'Semesterferien',\n",
    "                        'Feiertage',\n",
    "                        'KielerWoche',\n",
    "                        'Werktag']\n",
    "\n",
    "\n",
    "\n",
    "# Inspect data types and unique values for categorical columns\n",
    "print(data[categorical_features].dtypes)\n",
    "print(\"Unique Values:\\n\",data[categorical_features].apply(lambda x: x.unique()))\n",
    "\n",
    "# Ensure categorical columns are treated as categories\n",
    "for col in categorical_features:\n",
    "    data[col] = data[col].astype('category')\n",
    "\n",
    "# Encode categorical variables using pd.get_dummies\n",
    "features = pd.get_dummies(data[categorical_features], drop_first=True, dtype=int)\n",
    "\n",
    "# Include any numeric columns that are not categorical\n",
    "features['Inflationsrate'] = data['Inflationsrate']\n",
    "features['Temperatur'] = data['Temperatur']\n",
    "features['Niederschlag'] = data['Niederschlag']\n",
    "features['Schneehoehe'] = data['Schneehoehe']\n",
    "features['Sonnenschein'] = data['Sonnenschein']\n",
    "features['Warengruppe'] = data['Warengruppe']\n",
    "features['Datum'] = data['Datum']\n",
    "features['Kreuzfahrverkehr'] = data['Kreuzfahrverkehr']\n",
    "features['Faehrverkaehr'] = data['Faehrverkaehr']\n",
    "features['Monat'] = data['Monat']\n",
    "\n",
    "\n",
    "# Construct the prepared data set including the dependent variable --> Umsatz\n",
    "prepared_data = pd.concat([data[['Umsatz']], features], axis=1)\n",
    "\n",
    "\n",
    "# Wenn Data imputation fertig ist, #wegnehmen\n",
    "\n",
    "# Display the shape of the prepared data set\n",
    "#print(prepared_data.shape)\n",
    "# Display the first few rows of the prepared data set\n",
    "#prepared_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_Brot_W1:\n",
      "      Umsatz  Heimspiel_1.0  Weihnachtsmarkt_1.0  Markt_1.0  Frühling_1.0  \\\n",
      "2179     NaN              1                    0          0             0   \n",
      "2180     NaN              0                    0          0             0   \n",
      "2181     NaN              0                    0          0             0   \n",
      "2182     NaN              0                    0          0             0   \n",
      "2183     NaN              0                    0          0             0   \n",
      "\n",
      "      Sommer_1.0  Herbst_1.0  Winter_1.0  Temp_warm_1.0  Temp_cold_1.0  ...  \\\n",
      "2179           1           0           0              1              0  ...   \n",
      "2180           1           0           0              0              0  ...   \n",
      "2181           1           0           0              1              0  ...   \n",
      "2182           1           0           0              0              0  ...   \n",
      "2183           1           0           0              0              0  ...   \n",
      "\n",
      "      Inflationsrate  Temperatur  Niederschlag  Schneehoehe  Sonnenschein  \\\n",
      "2179            1.43     23.5375           0.0          0.0           0.0   \n",
      "2180            1.43     23.3500           0.3          0.0           0.0   \n",
      "2181            1.43     25.2500           2.1          0.0           0.0   \n",
      "2182            1.43     20.7375           4.2          0.0           0.0   \n",
      "2183            1.43     20.4500           9.9          0.0           0.0   \n",
      "\n",
      "      Warengruppe       Datum  Kreuzfahrverkehr  Faehrverkaehr  Monat  \n",
      "2179          NaN  2019-07-27     419447.006618   1.576718e+06    7.0  \n",
      "2180          NaN  2019-07-28     412164.984367   1.623741e+06    7.0  \n",
      "2181          NaN  2019-07-29     485497.014662   1.599375e+06    7.0  \n",
      "2182          NaN  2019-07-30     485497.000000   1.599375e+06    7.0  \n",
      "2183          NaN  2019-07-31     419447.005983   1.576718e+06    7.0  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "df_Broetchen_W2:\n",
      "      Umsatz  Heimspiel_1.0  Weihnachtsmarkt_1.0  Markt_1.0  Frühling_1.0  \\\n",
      "2179     NaN              1                    0          0             0   \n",
      "2180     NaN              0                    0          0             0   \n",
      "2181     NaN              0                    0          0             0   \n",
      "2182     NaN              0                    0          0             0   \n",
      "2183     NaN              0                    0          0             0   \n",
      "\n",
      "      Sommer_1.0  Herbst_1.0  Winter_1.0  Temp_warm_1.0  Temp_cold_1.0  ...  \\\n",
      "2179           1           0           0              1              0  ...   \n",
      "2180           1           0           0              0              0  ...   \n",
      "2181           1           0           0              1              0  ...   \n",
      "2182           1           0           0              0              0  ...   \n",
      "2183           1           0           0              0              0  ...   \n",
      "\n",
      "      Inflationsrate  Temperatur  Niederschlag  Schneehoehe  Sonnenschein  \\\n",
      "2179            1.43     23.5375           0.0          0.0           0.0   \n",
      "2180            1.43     23.3500           0.3          0.0           0.0   \n",
      "2181            1.43     25.2500           2.1          0.0           0.0   \n",
      "2182            1.43     20.7375           4.2          0.0           0.0   \n",
      "2183            1.43     20.4500           9.9          0.0           0.0   \n",
      "\n",
      "      Warengruppe       Datum  Kreuzfahrverkehr  Faehrverkaehr  Monat  \n",
      "2179          NaN  2019-07-27     419447.006618   1.576718e+06    7.0  \n",
      "2180          NaN  2019-07-28     412164.984367   1.623741e+06    7.0  \n",
      "2181          NaN  2019-07-29     485497.014662   1.599375e+06    7.0  \n",
      "2182          NaN  2019-07-30     485497.000000   1.599375e+06    7.0  \n",
      "2183          NaN  2019-07-31     419447.005983   1.576718e+06    7.0  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "df_Crossaint_W3:\n",
      "      Umsatz  Heimspiel_1.0  Weihnachtsmarkt_1.0  Markt_1.0  Frühling_1.0  \\\n",
      "2179     NaN              1                    0          0             0   \n",
      "2180     NaN              0                    0          0             0   \n",
      "2181     NaN              0                    0          0             0   \n",
      "2182     NaN              0                    0          0             0   \n",
      "2183     NaN              0                    0          0             0   \n",
      "\n",
      "      Sommer_1.0  Herbst_1.0  Winter_1.0  Temp_warm_1.0  Temp_cold_1.0  ...  \\\n",
      "2179           1           0           0              1              0  ...   \n",
      "2180           1           0           0              0              0  ...   \n",
      "2181           1           0           0              1              0  ...   \n",
      "2182           1           0           0              0              0  ...   \n",
      "2183           1           0           0              0              0  ...   \n",
      "\n",
      "      Inflationsrate  Temperatur  Niederschlag  Schneehoehe  Sonnenschein  \\\n",
      "2179            1.43     23.5375           0.0          0.0           0.0   \n",
      "2180            1.43     23.3500           0.3          0.0           0.0   \n",
      "2181            1.43     25.2500           2.1          0.0           0.0   \n",
      "2182            1.43     20.7375           4.2          0.0           0.0   \n",
      "2183            1.43     20.4500           9.9          0.0           0.0   \n",
      "\n",
      "      Warengruppe       Datum  Kreuzfahrverkehr  Faehrverkaehr  Monat  \n",
      "2179          NaN  2019-07-27     419447.006618   1.576718e+06    7.0  \n",
      "2180          NaN  2019-07-28     412164.984367   1.623741e+06    7.0  \n",
      "2181          NaN  2019-07-29     485497.014662   1.599375e+06    7.0  \n",
      "2182          NaN  2019-07-30     485497.000000   1.599375e+06    7.0  \n",
      "2183          NaN  2019-07-31     419447.005983   1.576718e+06    7.0  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "df_Konditorei_W4:\n",
      "      Umsatz  Heimspiel_1.0  Weihnachtsmarkt_1.0  Markt_1.0  Frühling_1.0  \\\n",
      "2126     NaN              1                    0          0             0   \n",
      "2127     NaN              0                    0          0             0   \n",
      "2128     NaN              0                    0          0             0   \n",
      "2129     NaN              0                    0          0             0   \n",
      "2130     NaN              0                    0          0             0   \n",
      "\n",
      "      Sommer_1.0  Herbst_1.0  Winter_1.0  Temp_warm_1.0  Temp_cold_1.0  ...  \\\n",
      "2126           1           0           0              1              0  ...   \n",
      "2127           1           0           0              0              0  ...   \n",
      "2128           1           0           0              1              0  ...   \n",
      "2129           1           0           0              0              0  ...   \n",
      "2130           1           0           0              0              0  ...   \n",
      "\n",
      "      Inflationsrate  Temperatur  Niederschlag  Schneehoehe  Sonnenschein  \\\n",
      "2126            1.43     23.5375           0.0          0.0           0.0   \n",
      "2127            1.43     23.3500           0.3          0.0           0.0   \n",
      "2128            1.43     25.2500           2.1          0.0           0.0   \n",
      "2129            1.43     20.7375           4.2          0.0           0.0   \n",
      "2130            1.43     20.4500           9.9          0.0           0.0   \n",
      "\n",
      "      Warengruppe       Datum  Kreuzfahrverkehr  Faehrverkaehr  Monat  \n",
      "2126          NaN  2019-07-27     419447.006618   1.576718e+06    7.0  \n",
      "2127          NaN  2019-07-28     412164.984367   1.623741e+06    7.0  \n",
      "2128          NaN  2019-07-29     485497.014662   1.599375e+06    7.0  \n",
      "2129          NaN  2019-07-30     485497.000000   1.599375e+06    7.0  \n",
      "2130          NaN  2019-07-31     419447.005983   1.576718e+06    7.0  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "df_Kuchen_W5:\n",
      "      Umsatz  Heimspiel_1.0  Weihnachtsmarkt_1.0  Markt_1.0  Frühling_1.0  \\\n",
      "2179     NaN              1                    0          0             0   \n",
      "2180     NaN              0                    0          0             0   \n",
      "2181     NaN              0                    0          0             0   \n",
      "2182     NaN              0                    0          0             0   \n",
      "2183     NaN              0                    0          0             0   \n",
      "\n",
      "      Sommer_1.0  Herbst_1.0  Winter_1.0  Temp_warm_1.0  Temp_cold_1.0  ...  \\\n",
      "2179           1           0           0              1              0  ...   \n",
      "2180           1           0           0              0              0  ...   \n",
      "2181           1           0           0              1              0  ...   \n",
      "2182           1           0           0              0              0  ...   \n",
      "2183           1           0           0              0              0  ...   \n",
      "\n",
      "      Inflationsrate  Temperatur  Niederschlag  Schneehoehe  Sonnenschein  \\\n",
      "2179            1.43     23.5375           0.0          0.0           0.0   \n",
      "2180            1.43     23.3500           0.3          0.0           0.0   \n",
      "2181            1.43     25.2500           2.1          0.0           0.0   \n",
      "2182            1.43     20.7375           4.2          0.0           0.0   \n",
      "2183            1.43     20.4500           9.9          0.0           0.0   \n",
      "\n",
      "      Warengruppe       Datum  Kreuzfahrverkehr  Faehrverkaehr  Monat  \n",
      "2179          NaN  2019-07-27     419447.006618   1.576718e+06    7.0  \n",
      "2180          NaN  2019-07-28     412164.984367   1.623741e+06    7.0  \n",
      "2181          NaN  2019-07-29     485497.014662   1.599375e+06    7.0  \n",
      "2182          NaN  2019-07-30     485497.000000   1.599375e+06    7.0  \n",
      "2183          NaN  2019-07-31     419447.005983   1.576718e+06    7.0  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "df_Saisonbrot_W6:\n",
      "     Umsatz  Heimspiel_1.0  Weihnachtsmarkt_1.0  Markt_1.0  Frühling_1.0  \\\n",
      "652     NaN              1                    0          0             0   \n",
      "653     NaN              0                    0          0             0   \n",
      "654     NaN              0                    0          0             0   \n",
      "655     NaN              0                    0          0             0   \n",
      "656     NaN              0                    0          0             0   \n",
      "\n",
      "     Sommer_1.0  Herbst_1.0  Winter_1.0  Temp_warm_1.0  Temp_cold_1.0  ...  \\\n",
      "652           1           0           0              1              0  ...   \n",
      "653           1           0           0              0              0  ...   \n",
      "654           1           0           0              1              0  ...   \n",
      "655           1           0           0              0              0  ...   \n",
      "656           1           0           0              0              0  ...   \n",
      "\n",
      "     Inflationsrate  Temperatur  Niederschlag  Schneehoehe  Sonnenschein  \\\n",
      "652            1.43     23.5375           0.0          0.0           0.0   \n",
      "653            1.43     23.3500           0.3          0.0           0.0   \n",
      "654            1.43     25.2500           2.1          0.0           0.0   \n",
      "655            1.43     20.7375           4.2          0.0           0.0   \n",
      "656            1.43     20.4500           9.9          0.0           0.0   \n",
      "\n",
      "     Warengruppe       Datum  Kreuzfahrverkehr  Faehrverkaehr  Monat  \n",
      "652          NaN  2019-07-27     419447.006618   1.576718e+06    7.0  \n",
      "653          NaN  2019-07-28     412164.984367   1.623741e+06    7.0  \n",
      "654          NaN  2019-07-29     485497.014662   1.599375e+06    7.0  \n",
      "655          NaN  2019-07-30     485497.000000   1.599375e+06    7.0  \n",
      "656          NaN  2019-07-31     419447.005983   1.576718e+06    7.0  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "#Splitting des Datensets in die jeweiligen Warengruppen\n",
    "\n",
    "#Bennenung der Warengruppne für dataframe Namen\n",
    "warengruppe_namen = {\n",
    "    1: 'Brot',\n",
    "    2: 'Broetchen',\n",
    "    3: 'Crossaint',\n",
    "    4: 'Konditorei',\n",
    "    5: 'Kuchen',\n",
    "    6: 'Saisonbrot'\n",
    "}\n",
    "\n",
    "# Ursprüngliche DataFrames filtern nach Warengruppe\n",
    "warengruppe_dataframes = {}\n",
    "for i, name in warengruppe_namen.items():\n",
    "    var_name = f\"df_{name}_W{i}\"  # Name erstellen nach: df_Brot_W1\n",
    "    warengruppe_dataframes[var_name] = prepared_data[\n",
    "        (prepared_data['Warengruppe'] == i) &\n",
    "        (prepared_data['Datum'] <= '2018-07-31')\n",
    "    ]\n",
    "\n",
    "# Daten bis 2019-07-31 unabhängig der Warengruppe hinzufügen\n",
    "new_data = prepared_data[\n",
    "    (prepared_data['Datum'] > '2018-07-31') &\n",
    "    (prepared_data['Datum'] <= '2019-08-31')\n",
    "]\n",
    "\n",
    "for var_name, df in warengruppe_dataframes.items():\n",
    "    updated_df = pd.concat([df, new_data], ignore_index=True)\n",
    "    globals()[var_name] = updated_df\n",
    "\n",
    "\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(\"df_Brot_W1:\")\n",
    "print(df_Brot_W1.tail()) #Luisa\n",
    "\n",
    "print(\"df_Broetchen_W2:\")\n",
    "print(df_Broetchen_W2.tail()) #Luisa\n",
    "\n",
    "print(\"df_Crossaint_W3:\")\n",
    "print(df_Crossaint_W3.tail()) #Nina\n",
    "\n",
    "print(\"df_Konditorei_W4:\")\n",
    "print(df_Konditorei_W4.tail()) #Wiebke\n",
    "\n",
    "print(\"df_Kuchen_W5:\")\n",
    "print(df_Kuchen_W5.tail()) #Nina\n",
    "\n",
    "print(\"df_Saisonbrot_W6:\")\n",
    "print(df_Saisonbrot_W6.tail()) #Wiebke\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W1_Brot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Sommer_1', 'Winter_1', 'Monday_1', 'Tuesday_1', 'Wednesday_1', 'Thursday_1', 'Friday_1', 'Saturday_1', 'Sunday_1'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m test_end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2019-07-30\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#Keep only wanted features\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m data\u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUmsatz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDatum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWarengruppe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#Hier Features hinzufügen und Namen anpassen:\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSommer_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWinter_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTemp_average_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTemp_warm_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTemp_cold_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFeiertage_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSchulferien_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSemesterferien_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMonday_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTuesday_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWednesday_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mThursday_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFriday_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSaturday_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSunday_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWeihnachtsmarkt_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMarkt_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHeimspiel_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mKielerWoche_1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Convert to datetime if not already\u001b[39;00m\n\u001b[1;32m     34\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatum\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatum\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Sommer_1', 'Winter_1', 'Monday_1', 'Tuesday_1', 'Wednesday_1', 'Thursday_1', 'Friday_1', 'Saturday_1', 'Sunday_1'] not in index\""
     ]
    }
   ],
   "source": [
    "data = df_Brot_W1\n",
    "\n",
    "# Define your date thresholds\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "test_end_date='2019-07-30'\n",
    "\n",
    "#Keep only wanted features\n",
    "data=data[['Umsatz',\n",
    "           'Datum',\n",
    "           'Warengruppe',\n",
    "            #Hier Features hinzufügen und Namen anpassen:\n",
    "           'Sommer_1',\n",
    "            'Winter_1',\n",
    "            'Temp_average_1.0',\n",
    "            'Temp_warm_1.0',\n",
    "            'Temp_cold_1.0',\n",
    "            'Feiertage_1.0',\n",
    "            'Schulferien_1.0',\n",
    "            'Semesterferien_1.0',\n",
    "            'Monday_1',\n",
    "            'Tuesday_1',\n",
    "            'Wednesday_1',\n",
    "            'Thursday_1',\n",
    "            'Friday_1',\n",
    "            'Saturday_1',\n",
    "            'Sunday_1',\n",
    "            'Weihnachtsmarkt_1.0',\n",
    "            'Markt_1.0',\n",
    "            'Heimspiel_1.0',\n",
    "            'KielerWoche_1.0']]\n",
    "\n",
    "# Convert to datetime if not already\n",
    "data['Datum'] = pd.to_datetime(data['Datum'])\n",
    "\n",
    "# Split the data based on the date thresholds\n",
    "training_data = data[data['Datum'] <= train_end_date]\n",
    "validation_data = data[(data['Datum'] > train_end_date) & (data['Datum'] <= validation_end_date)]\n",
    "test_data = data[(data['Datum'] > validation_end_date) & (data['Datum'] <= test_end_date)]\n",
    "\n",
    "# Separating features and labels\n",
    "training_features = training_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "validation_features = validation_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "test_features = test_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "\n",
    "training_labels = training_data[['Umsatz']]\n",
    "validation_labels = validation_data[['Umsatz']]\n",
    "test_labels = test_data[['Umsatz']]\n",
    "\n",
    "# Print dimensions of the dataframes\n",
    "print(\"Training features dimensions:\", training_features.shape)\n",
    "print(\"Validation features dimensions:\", validation_features.shape)\n",
    "print(\"Test features dimensions:\", test_features.shape)\n",
    "print()\n",
    "print(\"Training labels dimensions:\", training_labels.shape)\n",
    "print(\"Validation labels dimensions:\", validation_labels.shape)\n",
    "print(\"Test labels dimensions:\", test_labels.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectory for the pickle files\n",
    "subdirectory = \"pickle_data//W1_Brot_imputation\"\n",
    "os.makedirs(subdirectory, exist_ok=True)\n",
    "\n",
    "# Export of the prepared data to subdirectory as pickle files\n",
    "training_features.to_pickle(f\"{subdirectory}/training_features.pkl\")\n",
    "validation_features.to_pickle(f\"{subdirectory}/validation_features.pkl\")\n",
    "test_features.to_pickle(f\"{subdirectory}/test_features.pkl\")\n",
    "training_labels.to_pickle(f\"{subdirectory}/training_labels.pkl\")\n",
    "validation_labels.to_pickle(f\"{subdirectory}/validation_labels.pkl\")\n",
    "test_labels.to_pickle(f\"{subdirectory}/test_labels.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W2_Broetchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features dimensions: (1462, 5)\n",
      "Validation features dimensions: (357, 5)\n",
      "Test features dimensions: (364, 5)\n",
      "\n",
      "Training labels dimensions: (1462, 1)\n",
      "Validation labels dimensions: (357, 1)\n",
      "Test labels dimensions: (364, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22220/3320380203.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Datum'] = pd.to_datetime(data['Datum'])\n"
     ]
    }
   ],
   "source": [
    "data = df_Broetchen_W2\n",
    "\n",
    "# Define your date thresholds\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "test_end_date='2019-07-30'\n",
    "\n",
    "#Keep only wanted features\n",
    "data=data[['Umsatz',\n",
    "           'Datum',\n",
    "           'Warengruppe',\n",
    "            #Hier Features hinzufügen und Namen anpassen:\n",
    "           'Weihnachtsmarkt_1.0','Temperatur' ,'Friday_1.0','Sonnenschein','Werktag_1.0']]\n",
    "\n",
    "# Convert to datetime if not already\n",
    "data['Datum'] = pd.to_datetime(data['Datum'])\n",
    "\n",
    "# Split the data based on the date thresholds\n",
    "training_data = data[data['Datum'] <= train_end_date]\n",
    "validation_data = data[(data['Datum'] > train_end_date) & (data['Datum'] <= validation_end_date)]\n",
    "test_data = data[(data['Datum'] > validation_end_date) & (data['Datum'] <= test_end_date)]\n",
    "\n",
    "# Separating features and labels\n",
    "training_features = training_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "validation_features = validation_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "test_features = test_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "\n",
    "training_labels = training_data[['Umsatz']]\n",
    "validation_labels = validation_data[['Umsatz']]\n",
    "test_labels = test_data[['Umsatz']]\n",
    "\n",
    "# Print dimensions of the dataframes\n",
    "print(\"Training features dimensions:\", training_features.shape)\n",
    "print(\"Validation features dimensions:\", validation_features.shape)\n",
    "print(\"Test features dimensions:\", test_features.shape)\n",
    "print()\n",
    "print(\"Training labels dimensions:\", training_labels.shape)\n",
    "print(\"Validation labels dimensions:\", validation_labels.shape)\n",
    "print(\"Test labels dimensions:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectory for the pickle files\n",
    "subdirectory = \"pickle_data//W2_Broetchen_imputation\"\n",
    "os.makedirs(subdirectory, exist_ok=True)\n",
    "\n",
    "# Export of the prepared data to subdirectory as pickle files\n",
    "training_features.to_pickle(f\"{subdirectory}/training_features.pkl\")\n",
    "validation_features.to_pickle(f\"{subdirectory}/validation_features.pkl\")\n",
    "test_features.to_pickle(f\"{subdirectory}/test_features.pkl\")\n",
    "training_labels.to_pickle(f\"{subdirectory}/training_labels.pkl\")\n",
    "validation_labels.to_pickle(f\"{subdirectory}/validation_labels.pkl\")\n",
    "test_labels.to_pickle(f\"{subdirectory}/test_labels.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W3_Croissants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features dimensions: (1462, 17)\n",
      "Validation features dimensions: (357, 17)\n",
      "Test features dimensions: (364, 17)\n",
      "\n",
      "Training labels dimensions: (1462, 1)\n",
      "Validation labels dimensions: (357, 1)\n",
      "Test labels dimensions: (364, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22220/640115596.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Datum'] = pd.to_datetime(data['Datum'])\n"
     ]
    }
   ],
   "source": [
    "data = df_Crossaint_W3\n",
    "\n",
    "# Define your date thresholds\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "test_end_date='2019-07-30'\n",
    "\n",
    "#Keep only wanted features\n",
    "data=data[['Umsatz',\n",
    "           'Datum',\n",
    "           'Warengruppe',\n",
    "            #Hier Features hinzufügen und Namen anpassen:\n",
    "           'Sommer_1.0',\n",
    "           'Winter_1.0',\n",
    "           'Temp_cold_1.0',\n",
    "           'Temp_warm_1.0',\n",
    "           'Temp_average_1.0',\n",
    "           'Monday_1.0',\n",
    "           'Wednesday_1.0',\n",
    "           'Thursday_1.0',\n",
    "           'Saturday_1.0',\n",
    "           'Sunday_1.0',\n",
    "           'Schulferien_1.0',\n",
    "           'Semesterferien_1.0',\n",
    "           'Feiertage_1.0',\n",
    "           'Markt_1.0',   \n",
    "           'Sonnenschein',\n",
    "           'Niederschlag',\n",
    "           #'Tageslaenge (dezimal)',\n",
    "           'Weihnachtsmarkt_1.0']]\n",
    "\n",
    "# Convert to datetime if not already\n",
    "data['Datum'] = pd.to_datetime(data['Datum'])\n",
    "\n",
    "# Split the data based on the date thresholds\n",
    "training_data = data[data['Datum'] <= train_end_date]\n",
    "validation_data = data[(data['Datum'] > train_end_date) & (data['Datum'] <= validation_end_date)]\n",
    "test_data = data[(data['Datum'] > validation_end_date) & (data['Datum'] <= test_end_date)]\n",
    "\n",
    "# Separating features and labels\n",
    "training_features = training_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "validation_features = validation_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "test_features = test_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "\n",
    "training_labels = training_data[['Umsatz']]\n",
    "validation_labels = validation_data[['Umsatz']]\n",
    "test_labels = test_data[['Umsatz']]\n",
    "\n",
    "# Print dimensions of the dataframes\n",
    "print(\"Training features dimensions:\", training_features.shape)\n",
    "print(\"Validation features dimensions:\", validation_features.shape)\n",
    "print(\"Test features dimensions:\", test_features.shape)\n",
    "print()\n",
    "print(\"Training labels dimensions:\", training_labels.shape)\n",
    "print(\"Validation labels dimensions:\", validation_labels.shape)\n",
    "print(\"Test labels dimensions:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectory for the pickle files\n",
    "subdirectory = \"pickle_data//W3_Croissants_imputation\"\n",
    "os.makedirs(subdirectory, exist_ok=True)\n",
    "\n",
    "# Export of the prepared data to subdirectory as pickle files\n",
    "training_features.to_pickle(f\"{subdirectory}/training_features.pkl\")\n",
    "validation_features.to_pickle(f\"{subdirectory}/validation_features.pkl\")\n",
    "test_features.to_pickle(f\"{subdirectory}/test_features.pkl\")\n",
    "training_labels.to_pickle(f\"{subdirectory}/training_labels.pkl\")\n",
    "validation_labels.to_pickle(f\"{subdirectory}/validation_labels.pkl\")\n",
    "test_labels.to_pickle(f\"{subdirectory}/test_labels.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W4_Konditorei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features dimensions: (1409, 18)\n",
      "Validation features dimensions: (357, 18)\n",
      "Test features dimensions: (364, 18)\n",
      "\n",
      "Training labels dimensions: (1409, 1)\n",
      "Validation labels dimensions: (357, 1)\n",
      "Test labels dimensions: (364, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22220/3452932458.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Datum'] = pd.to_datetime(data['Datum'])\n"
     ]
    }
   ],
   "source": [
    "data = df_Konditorei_W4\n",
    "\n",
    "# Define your date thresholds\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "test_end_date='2019-07-30'\n",
    "\n",
    "#'Inflationsrate','Heimspiel','Markt', 'Temperatur', 'Schulferien','Sommer','Herbst','Temp_cold','Saturday','KielerWoche',\n",
    "          #  'Feiertage', 'Niederschlag','Schneehoehe','Sonnenschein','Weihnachtsmarkt','Monat','Semesterferien','Werktag'\n",
    "          # 'Sommer','Herbst','Temp_cold','Saturday','Semesterferien','Sonnenschein','KielerWoche','Werktag'\n",
    "#Keep only wanted features\n",
    "data=data[['Umsatz','Datum','Warengruppe','Inflationsrate','Heimspiel_1.0','Markt_1.0', 'Temperatur', 'Schulferien_1.0',\n",
    "           'Sommer_1.0','Herbst_1.0','Saturday_1.0','KielerWoche_1.0','Feiertage_1.0','Temp_cold_1.0', 'Niederschlag','Schneehoehe',\n",
    "           'Sonnenschein','Weihnachtsmarkt_1.0','Semesterferien_1.0','Werktag_1.0','Monat']]\n",
    "\n",
    "# Convert to datetime if not already\n",
    "data['Datum'] = pd.to_datetime(data['Datum'])\n",
    "\n",
    "# Split the data based on the date thresholds\n",
    "training_data = data[data['Datum'] <= train_end_date]\n",
    "validation_data = data[(data['Datum'] > train_end_date) & (data['Datum'] <= validation_end_date)]\n",
    "test_data = data[(data['Datum'] > validation_end_date) & (data['Datum'] <= test_end_date)]\n",
    "\n",
    "# Separating features and labels\n",
    "training_features = training_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "validation_features = validation_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "test_features = test_data.drop('Umsatz', axis=1).drop('Datum', axis=1).drop('Warengruppe', axis=1)\n",
    "\n",
    "training_labels = training_data[['Umsatz']]\n",
    "validation_labels = validation_data[['Umsatz']]\n",
    "test_labels = test_data[['Umsatz']]\n",
    "\n",
    "# Print dimensions of the dataframes\n",
    "print(\"Training features dimensions:\", training_features.shape)\n",
    "print(\"Validation features dimensions:\", validation_features.shape)\n",
    "print(\"Test features dimensions:\", test_features.shape)\n",
    "print()\n",
    "print(\"Training labels dimensions:\", training_labels.shape)\n",
    "print(\"Validation labels dimensions:\", validation_labels.shape)\n",
    "print(\"Test labels dimensions:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectory for the pickle files\n",
    "subdirectory = \"pickle_data//W4_Konditorei_imputation\"\n",
    "os.makedirs(subdirectory, exist_ok=True)\n",
    "\n",
    "# Export of the prepared data to subdirectory as pickle files\n",
    "training_features.to_pickle(f\"{subdirectory}/training_features.pkl\")\n",
    "validation_features.to_pickle(f\"{subdirectory}/validation_features.pkl\")\n",
    "test_features.to_pickle(f\"{subdirectory}/test_features.pkl\")\n",
    "training_labels.to_pickle(f\"{subdirectory}/training_labels.pkl\")\n",
    "validation_labels.to_pickle(f\"{subdirectory}/validation_labels.pkl\")\n",
    "test_labels.to_pickle(f\"{subdirectory}/test_labels.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W5_Kuchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features dimensions: (1462, 14)\n",
      "Validation features dimensions: (357, 14)\n",
      "Test features dimensions: (364, 14)\n",
      "\n",
      "Training labels dimensions: (1462, 1)\n",
      "Validation labels dimensions: (357, 1)\n",
      "Test labels dimensions: (364, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22220/1838783615.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Datum'] = pd.to_datetime(data['Datum'])\n"
     ]
    }
   ],
   "source": [
    "data = df_Kuchen_W5\n",
    "\n",
    "# Define your date thresholds\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "test_end_date='2019-07-30'\n",
    "\n",
    "#Keep only wanted features\n",
    "data=data[['Umsatz',\n",
    "           'Datum',\n",
    "           'Warengruppe',\n",
    "            #Hier Features hinzufügen und Namen anpassen:\n",
    "           'Markt_1.0',\n",
    "           'Sonnenschein',\n",
    "           'Niederschlag',\n",
    "           #'Tageslaenge (dezimal)',\n",
    "           'Sommer_1.0',\n",
    "           'Herbst_1.0',\n",
    "           'Winter_1.0',\n",
    "           'Wednesday_1.0',\n",
    "           'Friday_1.0',\n",
    "           'Saturday_1.0',\n",
    "           'Sunday_1.0',\n",
    "           'Semesterferien_1.0',\n",
    "           'Temp_average_1.0',\n",
    "           'KielerWoche_1.0',\n",
    "           'Werktag_1.0']]\n",
    "\n",
    "# Convert to datetime if not already\n",
    "data['Datum'] = pd.to_datetime(data['Datum'])\n",
    "\n",
    "# Split the data based on the date thresholds\n",
    "training_data = data[data['Datum'] <= train_end_date]\n",
    "validation_data = data[(data['Datum'] > train_end_date) & (data['Datum'] <= validation_end_date)]\n",
    "test_data = data[(data['Datum'] > validation_end_date) & (data['Datum'] <= test_end_date)]\n",
    "\n",
    "# Separating features and labels\n",
    "training_features = training_data.drop(['Umsatz','Datum','Warengruppe'], axis=1)\n",
    "validation_features = validation_data.drop(['Umsatz','Datum','Warengruppe'], axis=1)\n",
    "test_features = test_data.drop(['Umsatz','Datum','Warengruppe'], axis=1)\n",
    "\n",
    "training_labels = training_data[['Umsatz']]\n",
    "validation_labels = validation_data[['Umsatz']]\n",
    "test_labels = test_data[['Umsatz']]\n",
    "\n",
    "# Print dimensions of the dataframes\n",
    "print(\"Training features dimensions:\", training_features.shape)\n",
    "print(\"Validation features dimensions:\", validation_features.shape)\n",
    "print(\"Test features dimensions:\", test_features.shape)\n",
    "print()\n",
    "print(\"Training labels dimensions:\", training_labels.shape)\n",
    "print(\"Validation labels dimensions:\", validation_labels.shape)\n",
    "print(\"Test labels dimensions:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectory for the pickle files\n",
    "subdirectory = \"pickle_data//W5_Kuchen_imputation\"\n",
    "os.makedirs(subdirectory, exist_ok=True)\n",
    "\n",
    "# Export of the prepared data to subdirectory as pickle files\n",
    "training_features.to_pickle(f\"{subdirectory}/training_features.pkl\")\n",
    "validation_features.to_pickle(f\"{subdirectory}/validation_features.pkl\")\n",
    "test_features.to_pickle(f\"{subdirectory}/test_features.pkl\")\n",
    "training_labels.to_pickle(f\"{subdirectory}/training_labels.pkl\")\n",
    "validation_labels.to_pickle(f\"{subdirectory}/validation_labels.pkl\")\n",
    "test_labels.to_pickle(f\"{subdirectory}/test_labels.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W6_Saisonbrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Umsatz', 'Heimspiel_1.0', 'Weihnachtsmarkt_1.0', 'Markt_1.0',\n",
      "       'Frühling_1.0', 'Sommer_1.0', 'Herbst_1.0', 'Winter_1.0',\n",
      "       'Temp_warm_1.0', 'Temp_cold_1.0', 'Temp_average_1.0', 'Monday_1.0',\n",
      "       'Tuesday_1.0', 'Wednesday_1.0', 'Thursday_1.0', 'Friday_1.0',\n",
      "       'Saturday_1.0', 'Sunday_1.0', 'Schulferien_1.0', 'Semesterferien_1.0',\n",
      "       'Feiertage_1.0', 'KielerWoche_1.0', 'Werktag_1.0', 'Inflationsrate',\n",
      "       'Temperatur', 'Niederschlag', 'Schneehoehe', 'Sonnenschein',\n",
      "       'Warengruppe', 'Datum', 'Kreuzfahrverkehr', 'Faehrverkaehr', 'Monat'],\n",
      "      dtype='object')\n",
      "Training features dimensions: (236, 6)\n",
      "Validation features dimensions: (56, 6)\n",
      "Test features dimensions: (364, 6)\n",
      "\n",
      "Training labels dimensions: (236, 1)\n",
      "Validation labels dimensions: (56, 1)\n",
      "Test labels dimensions: (364, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22220/2534091180.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Datum'] = pd.to_datetime(data['Datum'])\n"
     ]
    }
   ],
   "source": [
    "data = df_Saisonbrot_W6\n",
    "print (data.columns)\n",
    "# Define your date thresholds\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "test_end_date='2019-07-30'\n",
    "\n",
    "#Keep only wanted features\n",
    "#'Weihnachtsmarkt','Temperatur','Monat' ,'Friday','Sonnenschein','Werktag'\n",
    "data=data[['Umsatz','Datum','Warengruppe','Weihnachtsmarkt_1.0','Temperatur' ,'Friday_1.0','Sonnenschein','Werktag_1.0','Monat']]\n",
    "\n",
    "# Convert to datetime if not already\n",
    "data['Datum'] = pd.to_datetime(data['Datum'])\n",
    "\n",
    "# Split the data based on the date thresholds\n",
    "training_data = data[data['Datum'] <= train_end_date]\n",
    "validation_data = data[(data['Datum'] > train_end_date) & (data['Datum'] <= validation_end_date)]\n",
    "test_data = data[(data['Datum'] > validation_end_date) & (data['Datum'] <= test_end_date)]\n",
    "\n",
    "# Separating features and labels\n",
    "training_features = training_data.drop(['Umsatz','Datum','Warengruppe'], axis=1)\n",
    "validation_features = validation_data.drop(['Umsatz','Datum','Warengruppe'], axis=1)\n",
    "test_features = test_data.drop(['Umsatz','Datum','Warengruppe'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "training_labels = training_data[['Umsatz']]\n",
    "validation_labels = validation_data[['Umsatz']]\n",
    "test_labels = test_data[['Umsatz']]\n",
    "\n",
    "# Print dimensions of the dataframes\n",
    "print(\"Training features dimensions:\", training_features.shape)\n",
    "print(\"Validation features dimensions:\", validation_features.shape)\n",
    "print(\"Test features dimensions:\", test_features.shape)\n",
    "print()\n",
    "print(\"Training labels dimensions:\", training_labels.shape)\n",
    "print(\"Validation labels dimensions:\", validation_labels.shape)\n",
    "print(\"Test labels dimensions:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectory for the pickle files\n",
    "subdirectory = \"pickle_data//W6_Saisonbrot_imputation\"\n",
    "os.makedirs(subdirectory, exist_ok=True)\n",
    "\n",
    "# Export of the prepared data to subdirectory as pickle files\n",
    "training_features.to_pickle(f\"{subdirectory}/training_features.pkl\")\n",
    "validation_features.to_pickle(f\"{subdirectory}/validation_features.pkl\")\n",
    "test_features.to_pickle(f\"{subdirectory}/test_features.pkl\")\n",
    "training_labels.to_pickle(f\"{subdirectory}/training_labels.pkl\")\n",
    "validation_labels.to_pickle(f\"{subdirectory}/validation_labels.pkl\")\n",
    "test_labels.to_pickle(f\"{subdirectory}/test_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
