{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variablen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Veranstaltungen (Weihnachtsmarkt, Dom (Freimärkte), Fußballspiele, Sonstige) -> Luisa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellung des csv.files \"veranstaltung_kiel\" mit Veranstaltungen aus jahrmarktnord.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchsuche 2019-Seite: https://jahrmarktnord.de/2019/\n",
      "Durchsuche archivierte Seiten bis Seite 83...\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/1/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/2/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/3/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/4/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/5/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/6/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/7/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/8/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/9/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/10/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/11/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/12/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/13/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/14/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/15/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/16/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/17/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/18/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/19/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/20/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/21/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/22/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/23/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/24/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/25/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/26/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/27/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/28/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/29/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/30/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/31/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/32/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/33/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/34/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/35/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/36/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/37/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/38/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/39/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/40/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/41/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/42/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/43/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/44/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/45/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/46/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/47/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/48/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/49/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/50/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/51/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/52/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/53/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/54/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/55/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/56/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/57/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/58/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/59/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/60/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/61/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/62/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/63/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/64/Abrufen von https://jahrmarktnord.de/category/archiv/page/65/\n",
      "\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/66/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/67/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/68/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/69/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/70/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/71/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/72/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/73/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/74/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/75/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/76/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/77/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/78/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/79/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/80/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/81/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/82/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/83/\n",
      "Fehler beim Abrufen von https://jahrmarktnord.de/category/archiv/page/83/. Status Code: 404\n",
      "Request-Fehler bei https://jahrmarktnord.de/category/archiv/page/4/: HTTPSConnectionPool(host='jahrmarktnord.de', port=443): Max retries exceeded with url: /category/archiv/page/4/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7e6db04b38f0>, 'Connection to jahrmarktnord.de timed out. (connect timeout=10)'))Request-Fehler bei https://jahrmarktnord.de/category/archiv/page/6/: HTTPSConnectionPool(host='jahrmarktnord.de', port=443): Max retries exceeded with url: /category/archiv/page/6/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7e6db12c44a0>, 'Connection to jahrmarktnord.de timed out. (connect timeout=10)'))\n",
      "Request-Fehler bei https://jahrmarktnord.de/category/archiv/page/3/: HTTPSConnectionPool(host='jahrmarktnord.de', port=443): Max retries exceeded with url: /category/archiv/page/3/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7e6db04b26f0>, 'Connection to jahrmarktnord.de timed out. (connect timeout=10)'))\n",
      "\n",
      "Daten wurden erfolgreich in die CSV-Datei geschrieben!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def fetch_and_extract_data():\n",
    "    # URL der Webseite\n",
    "    base_url = 'https://jahrmarktnord.de/category/archiv'  # Standard-Archiv-URL\n",
    "    year_2019_url = 'https://jahrmarktnord.de/2019/'  # Spezielle URL für 2019\n",
    "    event_data = []\n",
    "\n",
    "    # Abruf der 2019-Daten\n",
    "    print(f\"Durchsuche 2019-Seite: {year_2019_url}\")\n",
    "    response = requests.get(year_2019_url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        extract_events_from_page(soup, event_data)\n",
    "    else:\n",
    "        print(f\"Fehler beim Abrufen der 2019-Seite. Status Code: {response.status_code}\")\n",
    "\n",
    "    # Abruf der archivierten Jahre mit paralleler Verarbeitung (für alle 83 Seiten)\n",
    "    max_pages = 83  # 83 Seiten durchsuchen\n",
    "    print(f\"Durchsuche archivierte Seiten bis Seite {max_pages}...\")\n",
    "\n",
    "    # Paralleles Abrufen der Seiten\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        urls = [f\"{base_url}/page/{i}/\" for i in range(1, max_pages + 1)]\n",
    "        responses = list(executor.map(fetch_page, urls))\n",
    "    \n",
    "    # Extrahieren der Daten von allen Seiten\n",
    "    for response in responses:\n",
    "        if response:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            extract_events_from_page(soup, event_data)\n",
    "\n",
    "    # Daten in CSV speichern\n",
    "    if event_data:\n",
    "        write_to_csv(event_data)\n",
    "    else:\n",
    "        print(\"Keine relevanten Veranstaltungen gefunden.\")\n",
    "\n",
    "def fetch_page(url):\n",
    "    \"\"\"\n",
    "    Abrufen einer Seite. Rückgabe der Response bei Erfolg, sonst None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Abrufen von {url}\")\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return response\n",
    "        else:\n",
    "            print(f\"Fehler beim Abrufen von {url}. Status Code: {response.status_code}\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request-Fehler bei {url}: {e}\")\n",
    "    return None\n",
    "\n",
    "def extract_events_from_page(soup, event_data):\n",
    "    \"\"\"\n",
    "    Extrahiert Veranstaltungsdaten aus einer BeautifulSoup-Seite und fügt sie der event_data-Liste hinzu,\n",
    "    aber nur, wenn \"Kiel\" im Titel vorkommt.\n",
    "    \"\"\"\n",
    "    events = soup.find_all('article')\n",
    "    for event in events:\n",
    "        title_tag = event.find('h3', class_='entry-title')\n",
    "        if title_tag:\n",
    "            title = title_tag.text.strip()\n",
    "            if \"Kiel\" in title:\n",
    "                excerpt_tag = event.find('div', class_='mh-excerpt')\n",
    "                if excerpt_tag:\n",
    "                    excerpt_text = excerpt_tag.text.strip()\n",
    "                    date_match = re.search(r'(\\d{2}\\.\\d{2})(?:-(\\d{2}\\.\\d{2})(?:\\.(\\d{4}))?)?', excerpt_text)\n",
    "                    if date_match:\n",
    "                        start_date_raw = date_match.group(1)\n",
    "                        end_date_raw = date_match.group(2)\n",
    "                        year = date_match.group(3) or extract_year_from_title(title) or str(datetime.now().year)\n",
    "                        start_date = parse_date(start_date_raw, year)\n",
    "                        end_date = parse_date(end_date_raw or start_date_raw, year)\n",
    "                        event_data.append([title, start_date, end_date])\n",
    "\n",
    "def extract_year_from_title(title):\n",
    "    match = re.search(r'(\\d{4})', title)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def parse_date(date_str, year):\n",
    "    try:\n",
    "        if '.' in date_str:\n",
    "            date_obj = datetime.strptime(f\"{date_str}.{year}\", \"%d.%m.%Y\")\n",
    "            return date_obj.strftime(\"%Y-%m-%d\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Fehler beim Parsen des Datums '{date_str}': {e}\")\n",
    "    return None\n",
    "\n",
    "def write_to_csv(data):\n",
    "    with open('veranstaltungen_kiel_.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Event Name', 'Start Date (YYYY-MM-DD)', 'End Date (YYYY-MM-DD)'])\n",
    "        writer.writerows(data)\n",
    "        print(\"Daten wurden erfolgreich in die CSV-Datei geschrieben!\")\n",
    "\n",
    "# Aufruf der Funktion\n",
    "fetch_and_extract_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 2019 page: https://jahrmarktnord.de/2019/\n",
      "Fetching archive pages up to page 10...\n",
      "Fetching https://jahrmarktnord.de/category/archiv/page/1/\n",
      "Fetching https://jahrmarktnord.de/category/archiv/page/2/\n",
      "Fetching https://jahrmarktnord.de/category/archiv/page/3/\n",
      "Fetching https://jahrmarktnord.de/category/archiv/page/4/\n",
      "Fetching https://jahrmarktnord.de/category/archiv/page/5/\n",
      "Fetching https://jahrmarktnord.de/category/archiv/page/6/\n",
      "Fetching https://jahrmarktnord.de/category/archiv/page/7/\n",
      "Fetching https://jahrmarktnord.de/category/archiv/page/8/\n",
      "Fetching https://jahrmarktnord.de/category/archiv/page/9/\n",
      "Fetching https://jahrmarktnord.de/category/archiv/page/10/\n",
      "Request error on https://jahrmarktnord.de/category/archiv/page/4/: HTTPSConnectionPool(host='jahrmarktnord.de', port=443): Max retries exceeded with url: /category/archiv/page/4/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7e6db10996a0>, 'Connection to jahrmarktnord.de timed out. (connect timeout=10)'))\n",
      "Request error on https://jahrmarktnord.de/category/archiv/page/5/: HTTPSConnectionPool(host='jahrmarktnord.de', port=443): Max retries exceeded with url: /category/archiv/page/5/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7e6db109a210>, 'Connection to jahrmarktnord.de timed out. (connect timeout=10)'))\n",
      "Request error on https://jahrmarktnord.de/category/archiv/page/2/: HTTPSConnectionPool(host='jahrmarktnord.de', port=443): Max retries exceeded with url: /category/archiv/page/2/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7e6db1098200>, 'Connection to jahrmarktnord.de timed out. (connect timeout=10)'))\n",
      "Data successfully written to CSV file!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def fetch_and_extract_data():\n",
    "    base_url = 'https://jahrmarktnord.de/category/archiv'  # Archive URL\n",
    "    year_2019_url = 'https://jahrmarktnord.de/2019/'  # Special URL for 2019\n",
    "    event_data = []\n",
    "\n",
    "    # Fetch 2019 data\n",
    "    print(f\"Fetching 2019 page: {year_2019_url}\")\n",
    "    response = requests.get(year_2019_url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        extract_events_from_page(soup, event_data)\n",
    "    else:\n",
    "        print(f\"Error fetching 2019 page. Status Code: {response.status_code}\")\n",
    "\n",
    "    # Fetch archive years\n",
    "    max_pages = 10\n",
    "    print(f\"Fetching archive pages up to page {max_pages}...\")\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        urls = [f\"{base_url}/page/{i}/\" for i in range(1, max_pages + 1)]\n",
    "        responses = list(executor.map(fetch_page, urls))\n",
    "    \n",
    "    for response in responses:\n",
    "        if response:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            extract_events_from_page(soup, event_data)\n",
    "\n",
    "    # Write to CSV\n",
    "    if event_data:\n",
    "        write_to_csv(event_data)\n",
    "    else:\n",
    "        print(\"No relevant events found.\")\n",
    "\n",
    "def fetch_page(url):\n",
    "    \"\"\"\n",
    "    Fetch a single page. Return the response if successful, otherwise None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Fetching {url}\")\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return response\n",
    "        else:\n",
    "            print(f\"Error fetching {url}. Status Code: {response.status_code}\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request error on {url}: {e}\")\n",
    "    return None\n",
    "\n",
    "def extract_events_from_page(soup, event_data):\n",
    "    \"\"\"\n",
    "    Extracts event data from a BeautifulSoup page and appends to event_data.\n",
    "    \"\"\"\n",
    "    events = soup.find_all('article')\n",
    "    for event in events:\n",
    "        title_tag = event.find('h3', class_='entry-title')\n",
    "        if title_tag:\n",
    "            title = title_tag.text.strip()\n",
    "            is_kiel_event = \"Kiel\" in title and \"Kieler Umschlag\" not in title\n",
    "            is_kieler_umschlag = \"Kieler Umschlag\" in title\n",
    "            if is_kiel_event or is_kieler_umschlag:\n",
    "                excerpt_tag = event.find('div', class_='mh-excerpt')\n",
    "                if excerpt_tag:\n",
    "                    excerpt_text = excerpt_tag.text.strip()\n",
    "                    date_match = re.search(r'(\\d{2}\\.\\d{2})(?:-(\\d{2}\\.\\d{2})(?:\\.(\\d{4}))?)?', excerpt_text)\n",
    "                    if date_match:\n",
    "                        start_date_raw = date_match.group(1)\n",
    "                        end_date_raw = date_match.group(2)\n",
    "                        year = date_match.group(3) or extract_year_from_title(title) or str(datetime.now().year)\n",
    "                        start_date = parse_date(start_date_raw, year)\n",
    "                        end_date = parse_date(end_date_raw or start_date_raw, year)\n",
    "                        add_event_dates(event_data, start_date, end_date, is_kiel_event, is_kieler_umschlag)\n",
    "\n",
    "def extract_year_from_title(title):\n",
    "    \"\"\"\n",
    "    Extracts the year from the event title, if available.\n",
    "    \"\"\"\n",
    "    match = re.search(r'(\\d{4})', title)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def parse_date(date_str, year):\n",
    "    \"\"\"\n",
    "    Converts a date string (dd.mm or dd.mm.yyyy) to 'YYYY-MM-DD'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if '.' in date_str:\n",
    "            date_obj = datetime.strptime(f\"{date_str}.{year}\", \"%d.%m.%Y\")\n",
    "            return date_obj.strftime(\"%Y-%m-%d\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing date '{date_str}': {e}\")\n",
    "    return None\n",
    "\n",
    "def add_event_dates(event_data, start_date, end_date, is_kiel_event, is_kieler_umschlag):\n",
    "    \"\"\"\n",
    "    Adds all days of the event to the event_data list, including flags for 'Kiel' and 'Kieler Umschlag'.\n",
    "    \"\"\"\n",
    "    if start_date and end_date:\n",
    "        current_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        end_date_obj = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "        while current_date <= end_date_obj:\n",
    "            event_data.append([\n",
    "                current_date.strftime(\"%Y-%m-%d\"),\n",
    "                1 if is_kiel_event and not is_kieler_umschlag else 0,\n",
    "                1 if is_kieler_umschlag else 0\n",
    "            ])\n",
    "            current_date += timedelta(days=1)\n",
    "\n",
    "def write_to_csv(data):\n",
    "    \"\"\"\n",
    "    Writes event data to a CSV file.\n",
    "    \"\"\"\n",
    "    with open('veranstaltungen_Kiel_formatiert.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Date (YYYY-MM-DD)', 'Kiel Event (1 if true)', 'Kieler Umschlag (1 if true)'])\n",
    "        writer.writerows(data)\n",
    "        print(\"Data successfully written to 'veranstaltungen_Kiel_formatiert.csv'!\")\n",
    "\n",
    "# Call the function\n",
    "fetch_and_extract_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchsuche archivierte Seiten bis Seite 83...\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/1/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/2/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/3/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/4/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/5/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/6/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/7/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/8/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/9/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/10/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/11/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/12/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/13/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/14/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/15/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/16/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/17/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/18/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/19/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/20/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/21/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/22/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/23/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/24/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/25/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/26/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/27/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/28/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/29/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/30/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/31/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/32/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/33/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/34/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/35/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/36/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/37/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/38/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/39/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/40/Abrufen von https://jahrmarktnord.de/category/archiv/page/41/\n",
      "\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/42/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/43/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/44/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/45/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/46/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/47/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/48/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/49/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/50/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/51/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/52/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/53/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/54/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/55/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/56/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/57/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/58/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/59/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/60/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/61/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/62/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/63/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/64/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/65/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/66/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/67/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/68/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/69/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/70/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/71/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/72/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/73/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/74/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/75/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/76/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/77/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/78/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/79/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/80/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/81/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/82/\n",
      "Abrufen von https://jahrmarktnord.de/category/archiv/page/83/\n",
      "Fehler beim Abrufen von https://jahrmarktnord.de/category/archiv/page/83/. Status Code: 404\n",
      "Request-Fehler bei https://jahrmarktnord.de/category/archiv/page/9/: HTTPSConnectionPool(host='jahrmarktnord.de', port=443): Max retries exceeded with url: /category/archiv/page/9/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7250bccb40b0>, 'Connection to jahrmarktnord.de timed out. (connect timeout=10)'))\n",
      "Request-Fehler bei https://jahrmarktnord.de/category/archiv/page/8/: HTTPSConnectionPool(host='jahrmarktnord.de', port=443): Max retries exceeded with url: /category/archiv/page/8/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7250bccb70b0>, 'Connection to jahrmarktnord.de timed out. (connect timeout=10)'))\n",
      "Request-Fehler bei https://jahrmarktnord.de/category/archiv/page/10/: HTTPSConnectionPool(host='jahrmarktnord.de', port=443): Max retries exceeded with url: /category/archiv/page/10/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7250bccb50a0>, 'Connection to jahrmarktnord.de timed out. (connect timeout=10)'))\n",
      "Daten wurden erfolgreich in die CSV-Datei geschrieben!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def fetch_and_extract_data():\n",
    "    # URL der Webseite\n",
    "    base_url = 'https://jahrmarktnord.de/category/archiv'  # Standard-Archiv-URL\n",
    "    event_data = []\n",
    "\n",
    "    # Manuell hinzugefügte Kiel Märkte für 2019\n",
    "    manual_markets_2019 = [\n",
    "        ('2019-04-20', '2019-04-28', 1, 0),  # Kiel Frühjahrsmarkt\n",
    "        ('2019-09-27', '2019-10-06', 1, 0)   # Kiel Herbstmarkt\n",
    "    ]\n",
    "\n",
    "    # Hinzufügen der manuellen Markierungen\n",
    "    for start_date, end_date, kiel_event, kieler_umschlag in manual_markets_2019:\n",
    "        start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "        delta = end - start\n",
    "        for i in range(delta.days + 1):\n",
    "            current_date = start + timedelta(days=i)\n",
    "            event_data.append([current_date.strftime(\"%Y-%m-%d\"), kiel_event, kieler_umschlag])\n",
    "\n",
    "    # Abruf der archivierten Jahre mit paralleler Verarbeitung (für alle 83 Seiten)\n",
    "    max_pages = 83  # 83 Seiten durchsuchen\n",
    "    print(f\"Durchsuche archivierte Seiten bis Seite {max_pages}...\")\n",
    "\n",
    "    # Paralleles Abrufen der Seiten\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        urls = [f\"{base_url}/page/{i}/\" for i in range(1, max_pages + 1)]\n",
    "        responses = list(executor.map(fetch_page, urls))\n",
    "    \n",
    "    # Extrahieren der Daten von allen Seiten\n",
    "    for response in responses:\n",
    "        if response:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            extract_events_from_page(soup, event_data)\n",
    "\n",
    "    # Daten in CSV speichern\n",
    "    if event_data:\n",
    "        write_to_csv(event_data)\n",
    "    else:\n",
    "        print(\"Keine relevanten Veranstaltungen gefunden.\")\n",
    "\n",
    "def fetch_page(url):\n",
    "    \"\"\"\n",
    "    Abrufen einer Seite. Rückgabe der Response bei Erfolg, sonst None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Abrufen von {url}\")\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return response\n",
    "        else:\n",
    "            print(f\"Fehler beim Abrufen von {url}. Status Code: {response.status_code}\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request-Fehler bei {url}: {e}\")\n",
    "    return None\n",
    "\n",
    "def extract_events_from_page(soup, event_data):\n",
    "    \"\"\"\n",
    "    Extrahiert Veranstaltungsdaten aus einer BeautifulSoup-Seite und fügt sie der event_data-Liste hinzu,\n",
    "    mit spezifischen Regeln für Kiel-Events.\n",
    "    \"\"\"\n",
    "    events = soup.find_all('article')\n",
    "    for event in events:\n",
    "        title_tag = event.find('h3', class_='entry-title')\n",
    "        if title_tag:\n",
    "            title = title_tag.text.strip()\n",
    "            \n",
    "            # Explicitly exclude \"Kieler Woche\" events\n",
    "            if \"Kieler Woche\" in title:\n",
    "                continue\n",
    "            \n",
    "            # Check if event is in Kiel\n",
    "            if \"Kiel\" in title:\n",
    "                excerpt_tag = event.find('div', class_='mh-excerpt')\n",
    "                if excerpt_tag:\n",
    "                    excerpt_text = excerpt_tag.text.strip()\n",
    "                    date_match = re.search(r'(\\d{2}\\.\\d{2})(?:-(\\d{2}\\.\\d{2})(?:\\.(\\d{4}))?)?', excerpt_text)\n",
    "                    if date_match:\n",
    "                        start_date_raw = date_match.group(1)\n",
    "                        end_date_raw = date_match.group(2)\n",
    "                        year = date_match.group(3) or extract_year_from_title(title) or str(datetime.now().year)\n",
    "                        start_date = parse_date(start_date_raw, year)\n",
    "                        end_date = parse_date(end_date_raw or start_date_raw, year)\n",
    "\n",
    "                        # Determine event flags\n",
    "                        kiel_event = 0  # Default to 0\n",
    "                        kieler_umschlag = 0  # Default to 0\n",
    "                        \n",
    "                        # Special handling for \"Kieler Umschlag\"\n",
    "                        if \"Kieler Umschlag\" in title:\n",
    "                            kieler_umschlag = 1\n",
    "                        else:\n",
    "                            kiel_event = 1\n",
    "\n",
    "                        # Add each day from the event start to end\n",
    "                        event_dates = generate_event_dates(start_date, end_date)\n",
    "                        for event_date in event_dates:\n",
    "                            event_data.append([event_date, kiel_event, kieler_umschlag])\n",
    "\n",
    "def extract_year_from_title(title):\n",
    "    match = re.search(r'(\\d{4})', title)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def parse_date(date_str, year):\n",
    "    try:\n",
    "        if '.' in date_str:\n",
    "            date_obj = datetime.strptime(f\"{date_str}.{year}\", \"%d.%m.%Y\")\n",
    "            return date_obj.strftime(\"%Y-%m-%d\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Fehler beim Parsen des Datums '{date_str}': {e}\")\n",
    "    return None\n",
    "\n",
    "def generate_event_dates(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generates a list of dates from the start_date to the end_date.\n",
    "    \"\"\"\n",
    "    dates = []\n",
    "    start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    delta = end - start\n",
    "    for i in range(delta.days + 1):\n",
    "        current_date = start + timedelta(days=i)\n",
    "        dates.append(current_date.strftime(\"%Y-%m-%d\"))\n",
    "    return dates\n",
    "\n",
    "def write_to_csv(data):\n",
    "    with open('veranstaltungen_Kiel_formatiert.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Date (YYYY-MM-DD)', 'Kiel Event', 'Kieler Umschlag'])\n",
    "        writer.writerows(data)\n",
    "        print(\"Daten wurden erfolgreich in die CSV-Datei geschrieben!\")\n",
    "\n",
    "# Aufruf der Funktion\n",
    "fetch_and_extract_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
