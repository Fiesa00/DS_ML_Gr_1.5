{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural_net_estimation.ipynb einfach erstmal kopiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Define the file paths\n",
    "subdirectory = \"pickle_data\"\n",
    "training_features_path = f\"{subdirectory}/training_features.pkl\"\n",
    "validation_features_path = f\"{subdirectory}/validation_features.pkl\"\n",
    "test_features_path = f\"{subdirectory}/test_features.pkl\"\n",
    "training_labels_path = f\"{subdirectory}/training_labels.pkl\"\n",
    "validation_labels_path = f\"{subdirectory}/validation_labels.pkl\"\n",
    "test_labels_path = f\"{subdirectory}/test_labels.pkl\"\n",
    "\n",
    "# Read the pickle files\n",
    "training_features = pd.read_pickle(training_features_path)\n",
    "validation_features = pd.read_pickle(validation_features_path)\n",
    "test_features = pd.read_pickle(test_features_path)\n",
    "training_labels = pd.read_pickle(training_labels_path)\n",
    "validation_labels = pd.read_pickle(validation_labels_path)\n",
    "test_labels = pd.read_pickle(test_labels_path)\n",
    "\n",
    "# Verify the loaded data by printing their shapes and a few rows\n",
    "print(\"Loaded Training features dimensions:\", training_features.shape)\n",
    "print(\"Loaded Validation features dimensions:\", validation_features.shape)\n",
    "print(\"Loaded Test features dimensions:\", test_features.shape)\n",
    "print()\n",
    "print(\"Loaded Training labels dimensions:\", training_labels.shape)\n",
    "print(\"Loaded Validation labels dimensions:\", validation_labels.shape)\n",
    "print(\"Loaded Test labels dimensions:\", test_labels.shape)\n",
    "print()\n",
    "\n",
    "print(\"First few rows of loaded training features:\")\n",
    "print(training_features.head())\n",
    "print()\n",
    "print(\"First few rows of loaded training labels:\")\n",
    "print(training_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential([\n",
    "  InputLayer(shape=(training_features.shape[1], )),\n",
    "  BatchNormalization(),\n",
    "  Dense(10, activation='relu'),\n",
    "  Dense(4, activation='relu'),\n",
    "  Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=Adam(learning_rate=0.001))\n",
    "\n",
    "history = model.fit(training_features, training_labels, epochs=20,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"python_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss During Training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[non_zero_mask] - y_pred[non_zero_mask]) / y_true[non_zero_mask])) * 100\n",
    "\n",
    "training_predictions = model.predict(training_features)\n",
    "validation_predictions = model.predict(validation_features)\n",
    "print(f\"MAPE on the Training Data: {mape(training_labels, training_predictions):.2f}%\")\n",
    "print(f\"MAPE on the Validation Data: {mape(validation_labels, validation_predictions):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(data, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(data['actual'], label='Actual Values', color='red')\n",
    "    plt.plot(data['prediction'], label='Predicted Values', color='blue')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Case Number')\n",
    "    plt.ylabel('Price in 1.000 USD')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Ensure that training_predictions, validation_predictions, training_labels, and validation_labels are numpy arrays\n",
    "training_predictions = np.array(training_predictions).flatten()\n",
    "validation_predictions = np.array(validation_predictions).flatten()\n",
    "training_labels = np.array(training_labels).flatten()\n",
    "validation_labels = np.array(validation_labels).flatten()\n",
    "\n",
    "# print the type of the predictions\n",
    "print(type(training_predictions))\n",
    "print(type(validation_predictions))\n",
    "\n",
    "# Create DataFrames with 1-dimensional arrays\n",
    "data_train = pd.DataFrame({'prediction': training_predictions, 'actual': training_labels})\n",
    "data_validation = pd.DataFrame({'prediction': validation_predictions, 'actual': validation_labels})\n",
    "\n",
    "# Plot predictions\n",
    "plot_predictions(data_train.head(100), 'Predicted and Actual Values for the Training Data')\n",
    "plot_predictions(data_validation.head(100), 'Predicted and Actual Values for the Validation Data')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
